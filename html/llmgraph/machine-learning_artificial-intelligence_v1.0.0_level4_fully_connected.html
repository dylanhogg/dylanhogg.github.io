<html>
    <head>
        <meta charset="utf-8">
        
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-8GFQFYPREF"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-8GFQFYPREF');
        </script>

            <script>function neighbourhoodHighlight(params) {
  // console.log("in nieghbourhoodhighlight");
  allNodes = nodes.get({ returnType: "Object" });
  // originalNodes = JSON.parse(JSON.stringify(allNodes));
  // if something is selected:
  if (params.nodes.length > 0) {
    highlightActive = true;
    var i, j;
    var selectedNode = params.nodes[0];
    var degrees = 2;

    // mark all nodes as hard to read.
    for (let nodeId in allNodes) {
      // nodeColors[nodeId] = allNodes[nodeId].color;
      allNodes[nodeId].color = "rgba(200,200,200,0.5)";
      if (allNodes[nodeId].hiddenLabel === undefined) {
        allNodes[nodeId].hiddenLabel = allNodes[nodeId].label;
        allNodes[nodeId].label = undefined;
      }
    }
    var connectedNodes = network.getConnectedNodes(selectedNode);
    var allConnectedNodes = [];

    // get the second degree nodes
    for (i = 1; i < degrees; i++) {
      for (j = 0; j < connectedNodes.length; j++) {
        allConnectedNodes = allConnectedNodes.concat(
          network.getConnectedNodes(connectedNodes[j])
        );
      }
    }

    // all second degree nodes get a different color and their label back
    for (i = 0; i < allConnectedNodes.length; i++) {
      // allNodes[allConnectedNodes[i]].color = "pink";
      allNodes[allConnectedNodes[i]].color = "rgba(150,150,150,0.75)";
      if (allNodes[allConnectedNodes[i]].hiddenLabel !== undefined) {
        allNodes[allConnectedNodes[i]].label =
          allNodes[allConnectedNodes[i]].hiddenLabel;
        allNodes[allConnectedNodes[i]].hiddenLabel = undefined;
      }
    }

    // all first degree nodes get their own color and their label back
    for (i = 0; i < connectedNodes.length; i++) {
      // allNodes[connectedNodes[i]].color = undefined;
      allNodes[connectedNodes[i]].color = nodeColors[connectedNodes[i]];
      if (allNodes[connectedNodes[i]].hiddenLabel !== undefined) {
        allNodes[connectedNodes[i]].label =
          allNodes[connectedNodes[i]].hiddenLabel;
        allNodes[connectedNodes[i]].hiddenLabel = undefined;
      }
    }

    // the main node gets its own color and its label back.
    // allNodes[selectedNode].color = undefined;
    allNodes[selectedNode].color = nodeColors[selectedNode];
    if (allNodes[selectedNode].hiddenLabel !== undefined) {
      allNodes[selectedNode].label = allNodes[selectedNode].hiddenLabel;
      allNodes[selectedNode].hiddenLabel = undefined;
    }
  } else if (highlightActive === true) {
    // console.log("highlightActive was true");
    // reset all nodes
    for (let nodeId in allNodes) {
      // allNodes[nodeId].color = "purple";
      allNodes[nodeId].color = nodeColors[nodeId];
      // delete allNodes[nodeId].color;
      if (allNodes[nodeId].hiddenLabel !== undefined) {
        allNodes[nodeId].label = allNodes[nodeId].hiddenLabel;
        allNodes[nodeId].hiddenLabel = undefined;
      }
    }
    highlightActive = false;
  }

  // transform the object into an array
  var updateArray = [];
  if (params.nodes.length > 0) {
    for (let nodeId in allNodes) {
      if (allNodes.hasOwnProperty(nodeId)) {
        // console.log(allNodes[nodeId]);
        updateArray.push(allNodes[nodeId]);
      }
    }
    nodes.update(updateArray);
  } else {
    // console.log("Nothing was selected");
    for (let nodeId in allNodes) {
      if (allNodes.hasOwnProperty(nodeId)) {
        // console.log(allNodes[nodeId]);
        // allNodes[nodeId].color = {};
        updateArray.push(allNodes[nodeId]);
      }
    }
    nodes.update(updateArray);
  }
}

function filterHighlight(params) {
  allNodes = nodes.get({ returnType: "Object" });
  // if something is selected:
  if (params.nodes.length > 0) {
    filterActive = true;
    let selectedNodes = params.nodes;

    // hiding all nodes and saving the label
    for (let nodeId in allNodes) {
      allNodes[nodeId].hidden = true;
      if (allNodes[nodeId].savedLabel === undefined) {
        allNodes[nodeId].savedLabel = allNodes[nodeId].label;
        allNodes[nodeId].label = undefined;
      }
    }

    for (let i=0; i < selectedNodes.length; i++) {
      allNodes[selectedNodes[i]].hidden = false;
      if (allNodes[selectedNodes[i]].savedLabel !== undefined) {
        allNodes[selectedNodes[i]].label = allNodes[selectedNodes[i]].savedLabel;
        allNodes[selectedNodes[i]].savedLabel = undefined;
      }
    }

  } else if (filterActive === true) {
    // reset all nodes
    for (let nodeId in allNodes) {
      allNodes[nodeId].hidden = false;
      if (allNodes[nodeId].savedLabel !== undefined) {
        allNodes[nodeId].label = allNodes[nodeId].savedLabel;
        allNodes[nodeId].savedLabel = undefined;
      }
    }
    filterActive = false;
  }

  // transform the object into an array
  var updateArray = [];
  if (params.nodes.length > 0) {
    for (let nodeId in allNodes) {
      if (allNodes.hasOwnProperty(nodeId)) {
        updateArray.push(allNodes[nodeId]);
      }
    }
    nodes.update(updateArray);
  } else {
    for (let nodeId in allNodes) {
      if (allNodes.hasOwnProperty(nodeId)) {
        updateArray.push(allNodes[nodeId]);
      }
    }
    nodes.update(updateArray);
  }
}

function selectNode(nodes) {
  network.selectNodes(nodes);
  neighbourhoodHighlight({ nodes: nodes });
  return nodes;
}

function selectNodes(nodes) {
  network.selectNodes(nodes);
  filterHighlight({nodes: nodes});
  return nodes;
}

function highlightFilter(filter) {
  let selectedNodes = []
  let selectedProp = filter['property']
  if (filter['item'] === 'node') {
    let allNodes = nodes.get({ returnType: "Object" });
    for (let nodeId in allNodes) {
      if (allNodes[nodeId][selectedProp] && filter['value'].includes((allNodes[nodeId][selectedProp]).toString())) {
        selectedNodes.push(nodeId)
      }
    }
  }
  else if (filter['item'] === 'edge'){
    let allEdges = edges.get({returnType: 'object'});
    // check if the selected property exists for selected edge and select the nodes connected to the edge
    for (let edge in allEdges) {
      if (allEdges[edge][selectedProp] && filter['value'].includes((allEdges[edge][selectedProp]).toString())) {
        selectedNodes.push(allEdges[edge]['from'])
        selectedNodes.push(allEdges[edge]['to'])
      }
    }
  }
  selectNodes(selectedNodes)
}</script>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css" integrity="sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
            <script src="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js" integrity="sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            
            
            
            
            
            

        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork {
                 width: 100%;
                 height: 1200px;
                 background-color: #ffffff;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             

             
             #config {
                 float: left;
                 width: 400px;
                 height: 600px;
             }
             

             
             /* position absolute is important and the container has to be relative or absolute as well. */
          div.popup {
                 position:absolute;
                 top:0px;
                 left:0px;
                 display:none;
                 background-color:#f5f4ed;
                 -moz-border-radius: 3px;
                 -webkit-border-radius: 3px;
                 border-radius: 3px;
                 border: 1px solid #808074;
                 box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.2);
          }

          /* hide the original tooltip */
          .vis-tooltip {
            display:none;
          }
             
        </style>
    </head>


    <body>
        <div class="card" style="width: 100%">
            
            
            <div id="mynetwork" class="card-body"></div>
        </div>

        
        
            <div id="config"></div>
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"group": 4, "id": "Image segmentation", "label": "Image segmentation", "level": 4, "name": "Image segmentation", "node_count": 69, "processed": 2, "reason_for_similarity": "Both involve dividing an image into meaningful regions", "shape": "dot", "size": 10, "title": "69. \u003ca href=\u0027https://en.wikipedia.org/wiki/Image_segmentation\u0027 target=\u0027_blank\u0027\u003eImage segmentation\u003c/a\u003e\u003cbr /\u003eIn digital image processing and computer vision, image segmentation is the process of partitioning a digital image into multiple image segments, also known as image regions or image objects. The goal of segmentation is to simplify and/or change the representation of an image into something that is more meaningful and easier to analyze. Image segmentation is typically used to locate objects and boundaries in images. More precisely, image segmentation is the process of assigning a label to every p\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Image_segmentation", "wikipedia_content": "In digital image processing and computer vision, image segmentation is the process of partitioning a digital image into multiple image segments, also known as image regions or image objects. The goal of segmentation is to simplify and/or change the representation of an image into something that is more meaningful and easier to analyze. Image segmentation is typically used to locate objects and boundaries in images. More precisely, image segmentation is the process of assigning a label to every p", "wikipedia_link": "https://en.wikipedia.org/wiki/Image_segmentation", "wikipedia_normalized": "Image segmentation", "wikipedia_resp_code": 200}, {"group": 3, "id": "Object detection", "label": "Object detection", "level": 3, "name": "Object detection", "node_count": 21, "processed": 2, "reason_for_similarity": "Computer vision and object detection are closely related as both involve identifying and locating objects within images or videos.", "shape": "dot", "size": 10, "title": "21. \u003ca href=\u0027https://en.wikipedia.org/wiki/Object_detection\u0027 target=\u0027_blank\u0027\u003eObject detection\u003c/a\u003e\u003cbr /\u003eObject detection is a computer technology related to computer vision and image processing that deals with detecting instances of semantic objects of a certain class in digital images and videos. Well-researched domains of object detection include face detection and pedestrian detection. Object detection has applications in many areas of computer vision, including image retrieval and video surveillance.\u003cbr /\u003e[200, G3, L3, PR]", "wikipedia_canonical": "Object_detection", "wikipedia_content": "Object detection is a computer technology related to computer vision and image processing that deals with detecting instances of semantic objects of a certain class in digital images and videos. Well-researched domains of object detection include face detection and pedestrian detection. Object detection has applications in many areas of computer vision, including image retrieval and video surveillance.", "wikipedia_link": "https://en.wikipedia.org/wiki/Object_detection", "wikipedia_normalized": "Object detection", "wikipedia_resp_code": 200}, {"group": 500, "id": "Instance segmentation", "label": "Instance segmentation", "level": 3, "name": "Instance segmentation", "node_count": 23, "processed": 2, "reason_for_similarity": "Computer vision and instance segmentation share similarities as both involve identifying and delineating individual objects within an image.", "shape": "dot", "size": 10, "title": "23. \u003ca href=\u0027https://en.wikipedia.org/wiki/Instance_segmentation\u0027 target=\u0027_blank\u0027\u003eInstance segmentation\u003c/a\u003e\u003cbr /\u003e\u003cbr /\u003e[404, G500, L3, PR]", "wikipedia_canonical": "", "wikipedia_content": "", "wikipedia_link": "https://en.wikipedia.org/wiki/Instance_segmentation", "wikipedia_normalized": "", "wikipedia_resp_code": 404}, {"group": 3, "id": "Semantic segmentation", "label": "Semantic segmentation", "level": 3, "name": "Semantic segmentation", "node_count": 22, "processed": 2, "reason_for_similarity": "Computer vision and semantic segmentation are similar in that they both aim to assign semantic labels to different regions within an image.", "shape": "dot", "size": 10, "title": "22. \u003ca href=\u0027https://en.wikipedia.org/wiki/Semantic_segmentation\u0027 target=\u0027_blank\u0027\u003eSemantic segmentation\u003c/a\u003e \u2192 \u003ca href=\u0027https://en.wikipedia.org/wiki/Image_segmentation\u0027 target=\u0027_blank\u0027\u003eImage segmentation\u003c/a\u003e\u003cbr /\u003eIn digital image processing and computer vision, image segmentation is the process of partitioning a digital image into multiple image segments, also known as image regions or image objects. The goal of segmentation is to simplify and/or change the representation of an image into something that is more meaningful and easier to analyze. Image segmentation is typically used to locate objects and boundaries in images. More precisely, image segmentation is the process of assigning a label to every p\u003cbr /\u003e[200, G3, L3, PR]", "wikipedia_canonical": "Image_segmentation", "wikipedia_content": "In digital image processing and computer vision, image segmentation is the process of partitioning a digital image into multiple image segments, also known as image regions or image objects. The goal of segmentation is to simplify and/or change the representation of an image into something that is more meaningful and easier to analyze. Image segmentation is typically used to locate objects and boundaries in images. More precisely, image segmentation is the process of assigning a label to every p", "wikipedia_link": "https://en.wikipedia.org/wiki/Semantic_segmentation", "wikipedia_normalized": "Image segmentation", "wikipedia_resp_code": 200}, {"group": 3, "id": "Convolutional neural network", "label": "Convolutional neural network", "level": 3, "name": "Convolutional Neural Networks (CNNs)", "node_count": 7, "processed": 2, "reason_for_similarity": "Deep learning and CNNs are both neural network architectures commonly used in computer vision tasks, as they can effectively learn hierarchical representations from images.", "shape": "dot", "size": 10, "title": "7. \u003ca href=\u0027https://en.wikipedia.org/wiki/Convolutional_neural_network\u0027 target=\u0027_blank\u0027\u003eConvolutional neural network\u003c/a\u003e\u003cbr /\u003eConvolutional neural network (CNN) is a regularized type of feed-forward neural network that learns feature engineering by itself via filters optimization. Vanishing gradients and exploding gradients, seen during backpropagation in earlier neural networks, are prevented by using regularized weights over fewer connections. For example, for each neuron in the fully-connected layer 10,000 weights would be required for processing an image sized 100 \u00d7 100 pixels. However, applying cascaded convolutio\u003cbr /\u003e[200, G3, L3, PR]", "wikipedia_canonical": "Convolutional_neural_network", "wikipedia_content": "Convolutional neural network (CNN) is a regularized type of feed-forward neural network that learns feature engineering by itself via filters optimization. Vanishing gradients and exploding gradients, seen during backpropagation in earlier neural networks, are prevented by using regularized weights over fewer connections. For example, for each neuron in the fully-connected layer 10,000 weights would be required for processing an image sized 100 \u00d7 100 pixels. However, applying cascaded convolutio", "wikipedia_link": "https://en.wikipedia.org/wiki/Convolutional_neural_network", "wikipedia_normalized": "Convolutional neural network", "wikipedia_resp_code": 200}, {"group": 3, "id": "Recurrent neural network", "label": "Recurrent neural network", "level": 3, "name": "Recurrent Neural Networks (RNNs)", "node_count": 6, "processed": 2, "reason_for_similarity": "Both deep learning and RNNs are neural network architectures that can handle sequential data and capture temporal dependencies.", "shape": "dot", "size": 10, "title": "6. \u003ca href=\u0027https://en.wikipedia.org/wiki/Recurrent_neural_network\u0027 target=\u0027_blank\u0027\u003eRecurrent neural network\u003c/a\u003e\u003cbr /\u003eA recurrent neural network (RNN) is one of the two broad types of artificial neural network, characterized by direction of the flow of information between its layers. In contrast to the uni-directional feedforward neural network, it is a bi-directional artificial neural network, meaning that it allows the output from some nodes to affect subsequent input to the same nodes. Their ability to use internal state (memory) to process arbitrary sequences of inputs makes them applicable to tasks such as\u003cbr /\u003e[200, G3, L3, PR]", "wikipedia_canonical": "Recurrent_neural_network", "wikipedia_content": "A recurrent neural network (RNN) is one of the two broad types of artificial neural network, characterized by direction of the flow of information between its layers. In contrast to the uni-directional feedforward neural network, it is a bi-directional artificial neural network, meaning that it allows the output from some nodes to affect subsequent input to the same nodes. Their ability to use internal state (memory) to process arbitrary sequences of inputs makes them applicable to tasks such as", "wikipedia_link": "https://en.wikipedia.org/wiki/Recurrent_neural_network", "wikipedia_normalized": "Recurrent neural network", "wikipedia_resp_code": 200}, {"group": 2, "id": "Generative adversarial network", "label": "Generative adversarial network", "level": 2, "name": "Generative adversarial networks", "node_count": 5, "processed": 2, "reason_for_similarity": "Generative adversarial networks (GANs) are a class of machine learning models that consist of two neural networks: a generator and a discriminator. GANs are used to generate new data instances that resemble a given training dataset. This concept aligns with the goal of artificial intelligence to create systems that can generate new content or data.", "shape": "dot", "size": 10, "title": "5. \u003ca href=\u0027https://en.wikipedia.org/wiki/Generative_adversarial_network\u0027 target=\u0027_blank\u0027\u003eGenerative adversarial network\u003c/a\u003e\u003cbr /\u003eA generative adversarial network (GAN) is a class of machine learning framework and a prominent framework for approaching generative AI. The concept was initially developed by Ian Goodfellow and his colleagues in June 2014. In a GAN, two neural networks contest with each other in the form of a zero-sum game, where one agent\u0027s gain is another agent\u0027s loss.\u003cbr /\u003e[200, G2, L2, PR]", "wikipedia_canonical": "Generative_adversarial_network", "wikipedia_content": "A generative adversarial network (GAN) is a class of machine learning framework and a prominent framework for approaching generative AI. The concept was initially developed by Ian Goodfellow and his colleagues in June 2014. In a GAN, two neural networks contest with each other in the form of a zero-sum game, where one agent\u0027s gain is another agent\u0027s loss.", "wikipedia_link": "https://en.wikipedia.org/wiki/Generative_adversarial_network", "wikipedia_normalized": "Generative adversarial network", "wikipedia_resp_code": 200}, {"group": 4, "id": "Deep belief network", "label": "Deep belief network", "level": 4, "name": "Deep belief network", "node_count": 33, "processed": 2, "reason_for_similarity": "Convolutional neural networks (CNNs) and deep belief networks (DBNs) are both deep learning architectures. CNNs are primarily used for image and video processing tasks, while DBNs are used for unsupervised learning and feature extraction. Both CNNs and DBNs have multiple layers of neurons with learnable weights, and they can be trained using backpropagation algorithms.", "shape": "dot", "size": 10, "title": "33. \u003ca href=\u0027https://en.wikipedia.org/wiki/Deep_belief_network\u0027 target=\u0027_blank\u0027\u003eDeep belief network\u003c/a\u003e\u003cbr /\u003eIn machine learning, a deep belief network (DBN) is a generative graphical model, or alternatively a class of deep neural network, composed of multiple layers of latent variables, with connections between the layers but not between units within each layer.\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Deep_belief_network", "wikipedia_content": "In machine learning, a deep belief network (DBN) is a generative graphical model, or alternatively a class of deep neural network, composed of multiple layers of latent variables, with connections between the layers but not between units within each layer.", "wikipedia_link": "https://en.wikipedia.org/wiki/Deep_belief_network", "wikipedia_normalized": "Deep belief network", "wikipedia_resp_code": 200}, {"group": 3, "id": "Long short-term memory", "label": "Long short-term memory", "level": 3, "name": "Long Short-Term Memory (LSTM)", "node_count": 8, "processed": 2, "reason_for_similarity": "LSTMs are a type of recurrent neural network architecture that can effectively capture long-term dependencies in sequential data. Deep learning and LSTMs are both used in tasks involving sequential data analysis.", "shape": "dot", "size": 10, "title": "8. \u003ca href=\u0027https://en.wikipedia.org/wiki/Long_short-term_memory\u0027 target=\u0027_blank\u0027\u003eLong short-term memory\u003c/a\u003e\u003cbr /\u003eLong short-term memory (LSTM) network is a recurrent neural network (RNN), aimed to deal with the vanishing gradient problem present in traditional RNNs. Its relative insensitivity to gap length is its advantage over other RNNs, hidden Markov models and other sequence learning methods. It aims to provide a short-term memory for RNN that can last thousands of timesteps, thus \"long short-term memory\". It is applicable to classification, processing and predicting data based on time series, such as \u003cbr /\u003e[200, G3, L3, PR]", "wikipedia_canonical": "Long_short-term_memory", "wikipedia_content": "Long short-term memory (LSTM) network is a recurrent neural network (RNN), aimed to deal with the vanishing gradient problem present in traditional RNNs. Its relative insensitivity to gap length is its advantage over other RNNs, hidden Markov models and other sequence learning methods. It aims to provide a short-term memory for RNN that can last thousands of timesteps, thus \"long short-term memory\". It is applicable to classification, processing and predicting data based on time series, such as ", "wikipedia_link": "https://en.wikipedia.org/wiki/Long_short-term_memory", "wikipedia_normalized": "Long short-term memory", "wikipedia_resp_code": 200}, {"group": 3, "id": "Autoencoder", "label": "Autoencoder", "level": 3, "name": "Autoencoders", "node_count": 9, "processed": 2, "reason_for_similarity": "Deep learning and autoencoders are both neural network-based approaches. Autoencoders are unsupervised learning models that can learn efficient representations of input data by reconstructing it from a compressed latent space.", "shape": "dot", "size": 10, "title": "9. \u003ca href=\u0027https://en.wikipedia.org/wiki/Autoencoder\u0027 target=\u0027_blank\u0027\u003eAutoencoder\u003c/a\u003e\u003cbr /\u003eAn autoencoder is a type of artificial neural network used to learn efficient codings of unlabeled data. An autoencoder learns two functions: an encoding function that transforms the input data, and a decoding function that recreates the input data from the encoded representation. The autoencoder learns an efficient representation (encoding) for a set of data, typically for dimensionality reduction.\u003cbr /\u003e[200, G3, L3, PR]", "wikipedia_canonical": "Autoencoder", "wikipedia_content": "An autoencoder is a type of artificial neural network used to learn efficient codings of unlabeled data. An autoencoder learns two functions: an encoding function that transforms the input data, and a decoding function that recreates the input data from the encoded representation. The autoencoder learns an efficient representation (encoding) for a set of data, typically for dimensionality reduction.", "wikipedia_link": "https://en.wikipedia.org/wiki/Autoencoder", "wikipedia_normalized": "Autoencoder", "wikipedia_resp_code": 200}, {"group": 500, "id": "Sequence-to-sequence model", "label": "Sequence-to-sequence model", "level": 4, "name": "Sequence-to-Sequence (Seq2Seq) models", "node_count": 30, "processed": 2, "reason_for_similarity": "Seq2Seq models are used for tasks such as machine translation, where an input sequence is transformed into an output sequence. Recurrent neural networks, including LSTM and GRU, are commonly used as the underlying architecture for Seq2Seq models.", "shape": "dot", "size": 10, "title": "30. \u003ca href=\u0027https://en.wikipedia.org/wiki/Sequence-to-sequence_model\u0027 target=\u0027_blank\u0027\u003eSequence-to-sequence model\u003c/a\u003e\u003cbr /\u003e\u003cbr /\u003e[404, G500, L4, PR]", "wikipedia_canonical": "", "wikipedia_content": "", "wikipedia_link": "https://en.wikipedia.org/wiki/Sequence-to-sequence_model", "wikipedia_normalized": "", "wikipedia_resp_code": 404}, {"group": 4, "id": "Transformer (machine learning model)", "label": "Transformer (machine learning model)", "level": 4, "name": "Transformer", "node_count": 32, "processed": 2, "reason_for_similarity": "The Transformer model is a type of neural network architecture that has gained popularity for tasks such as machine translation and natural language processing. It utilizes self-attention mechanisms to capture dependencies between different positions in the input sequence, similar to how recurrent neural networks capture dependencies over time.", "shape": "dot", "size": 10, "title": "32. \u003ca href=\u0027https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)\u0027 target=\u0027_blank\u0027\u003eTransformer (machine learning model)\u003c/a\u003e\u003cbr /\u003eA transformer is a deep learning architecture that relies on the parallel multi-head attention mechanism. The modern transformer was proposed in the 2017 paper titled \u0027Attention Is All You Need\u0027 by Ashish Vaswani et al., Google Brain team. It is notable for requiring less training time than previous recurrent neural architectures, such as long short-term memory (LSTM), and its later variation has been prevalently adopted for training large language models on large (language) datasets, such as th\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Transformer_(machine_learning_model)", "wikipedia_content": "A transformer is a deep learning architecture that relies on the parallel multi-head attention mechanism. The modern transformer was proposed in the 2017 paper titled \u0027Attention Is All You Need\u0027 by Ashish Vaswani et al., Google Brain team. It is notable for requiring less training time than previous recurrent neural architectures, such as long short-term memory (LSTM), and its later variation has been prevalently adopted for training large language models on large (language) datasets, such as th", "wikipedia_link": "https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)", "wikipedia_normalized": "Transformer (machine learning model)", "wikipedia_resp_code": 200}, {"group": 500, "id": "Gating mechanism", "label": "Gating mechanism", "level": 4, "name": "Gating Mechanisms in Neural Networks", "node_count": 34, "processed": 2, "reason_for_similarity": "LSTM utilizes gating mechanisms to control the flow of information through the network, similar to other neural network architectures that use gating mechanisms.", "shape": "dot", "size": 10, "title": "34. \u003ca href=\u0027https://en.wikipedia.org/wiki/Gating_mechanism\u0027 target=\u0027_blank\u0027\u003eGating mechanism\u003c/a\u003e\u003cbr /\u003e\u003cbr /\u003e[404, G500, L4, PR]", "wikipedia_canonical": "", "wikipedia_content": "", "wikipedia_link": "https://en.wikipedia.org/wiki/Gating_mechanism", "wikipedia_normalized": "", "wikipedia_resp_code": 404}, {"group": 4, "id": "Gated recurrent unit", "label": "Gated recurrent unit", "level": 4, "name": "Gated Recurrent Unit (GRU)", "node_count": 29, "processed": 2, "reason_for_similarity": "GRU is another type of recurrent neural network that is similar to LSTM. It also addresses the vanishing gradient problem and can learn long-term dependencies, but with a simpler architecture compared to LSTM.", "shape": "dot", "size": 10, "title": "29. \u003ca href=\u0027https://en.wikipedia.org/wiki/Gated_recurrent_unit\u0027 target=\u0027_blank\u0027\u003eGated recurrent unit\u003c/a\u003e\u003cbr /\u003eGated recurrent units (GRUs) are a gating mechanism in recurrent neural networks, introduced in 2014 by Kyunghyun Cho et al. The GRU is like a long short-term memory (LSTM) with a forget gate, but has fewer parameters than LSTM, as it lacks an output gate. \nGRU\u0027s performance on certain tasks of polyphonic music modeling, speech signal modeling and natural language processing was found to be similar to that of LSTM. GRUs showed that gating is indeed helpful in general, and Bengio\u0027s team came to n\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Gated_recurrent_unit", "wikipedia_content": "Gated recurrent units (GRUs) are a gating mechanism in recurrent neural networks, introduced in 2014 by Kyunghyun Cho et al. The GRU is like a long short-term memory (LSTM) with a forget gate, but has fewer parameters than LSTM, as it lacks an output gate. \nGRU\u0027s performance on certain tasks of polyphonic music modeling, speech signal modeling and natural language processing was found to be similar to that of LSTM. GRUs showed that gating is indeed helpful in general, and Bengio\u0027s team came to n", "wikipedia_link": "https://en.wikipedia.org/wiki/Gated_recurrent_unit", "wikipedia_normalized": "Gated recurrent unit", "wikipedia_resp_code": 200}, {"group": 4, "id": "Part-of-speech tagging", "label": "Part-of-speech tagging", "level": 4, "name": "Part-of-speech tagging", "node_count": 63, "processed": 2, "reason_for_similarity": "Both Named-entity recognition and Part-of-speech tagging are natural language processing tasks that involve analyzing and categorizing words in a sentence.", "shape": "dot", "size": 10, "title": "63. \u003ca href=\u0027https://en.wikipedia.org/wiki/Part-of-speech_tagging\u0027 target=\u0027_blank\u0027\u003ePart-of-speech tagging\u003c/a\u003e\u003cbr /\u003eIn corpus linguistics, part-of-speech tagging, also called grammatical tagging is the process of marking up a word in a text (corpus) as corresponding to a particular part of speech, based on both its definition and its context.\nA simplified form of this is commonly taught to school-age children, in the identification of words as nouns, verbs, adjectives, adverbs, etc.\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Part-of-speech_tagging", "wikipedia_content": "In corpus linguistics, part-of-speech tagging, also called grammatical tagging is the process of marking up a word in a text (corpus) as corresponding to a particular part of speech, based on both its definition and its context.\nA simplified form of this is commonly taught to school-age children, in the identification of words as nouns, verbs, adjectives, adverbs, etc.", "wikipedia_link": "https://en.wikipedia.org/wiki/Part-of-speech_tagging", "wikipedia_normalized": "Part-of-speech tagging", "wikipedia_resp_code": 200}, {"group": 3, "id": "Text classification", "label": "Text classification", "level": 3, "name": "Text classification", "node_count": 15, "processed": 2, "reason_for_similarity": "Both involve processing and understanding textual data.", "shape": "dot", "size": 10, "title": "15. \u003ca href=\u0027https://en.wikipedia.org/wiki/Text_classification\u0027 target=\u0027_blank\u0027\u003eText classification\u003c/a\u003e \u2192 \u003ca href=\u0027https://en.wikipedia.org/wiki/Document_classification\u0027 target=\u0027_blank\u0027\u003eDocument classification\u003c/a\u003e\u003cbr /\u003eDocument classification or document categorization is a problem in library science, information science and computer science. The task is to assign a document to one or more classes or categories. This may be done \"manually\" or algorithmically. The intellectual classification of documents has mostly been the province of library science, while the algorithmic classification of documents is mainly in information science and computer science. The problems are overlapping, however, and there is ther\u003cbr /\u003e[200, G3, L3, PR]", "wikipedia_canonical": "Document_classification", "wikipedia_content": "Document classification or document categorization is a problem in library science, information science and computer science. The task is to assign a document to one or more classes or categories. This may be done \"manually\" or algorithmically. The intellectual classification of documents has mostly been the province of library science, while the algorithmic classification of documents is mainly in information science and computer science. The problems are overlapping, however, and there is ther", "wikipedia_link": "https://en.wikipedia.org/wiki/Text_classification", "wikipedia_normalized": "Document classification", "wikipedia_resp_code": 200}, {"group": 3, "id": "Sentiment analysis", "label": "Sentiment analysis", "level": 3, "name": "Sentiment analysis", "node_count": 19, "processed": 2, "reason_for_similarity": "Both involve understanding and analyzing the sentiment expressed in text.", "shape": "dot", "size": 10, "title": "19. \u003ca href=\u0027https://en.wikipedia.org/wiki/Sentiment_analysis\u0027 target=\u0027_blank\u0027\u003eSentiment analysis\u003c/a\u003e\u003cbr /\u003e\nSentiment analysis is the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information. Sentiment analysis is widely applied to voice of the customer materials such as reviews and survey responses, online and social media, and healthcare materials for applications that range from marketing to customer service to clinical medicine. With the rise of deep language mo\u003cbr /\u003e[200, G3, L3, PR]", "wikipedia_canonical": "Sentiment_analysis", "wikipedia_content": "\nSentiment analysis is the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information. Sentiment analysis is widely applied to voice of the customer materials such as reviews and survey responses, online and social media, and healthcare materials for applications that range from marketing to customer service to clinical medicine. With the rise of deep language mo", "wikipedia_link": "https://en.wikipedia.org/wiki/Sentiment_analysis", "wikipedia_normalized": "Sentiment analysis", "wikipedia_resp_code": 200}, {"group": 500, "id": "Dependency parsing", "label": "Dependency parsing", "level": 4, "name": "Dependency parsing", "node_count": 64, "processed": 2, "reason_for_similarity": "Both Named-entity recognition and Dependency parsing are tasks in natural language processing that involve analyzing the grammatical structure of sentences.", "shape": "dot", "size": 10, "title": "64. \u003ca href=\u0027https://en.wikipedia.org/wiki/Dependency_parsing\u0027 target=\u0027_blank\u0027\u003eDependency parsing\u003c/a\u003e\u003cbr /\u003e\u003cbr /\u003e[404, G500, L4, PR]", "wikipedia_canonical": "", "wikipedia_content": "", "wikipedia_link": "https://en.wikipedia.org/wiki/Dependency_parsing", "wikipedia_normalized": "", "wikipedia_resp_code": 404}, {"group": 4, "id": "Partially observable Markov decision process", "label": "Partially observable Markov decision process", "level": 4, "name": "Partially Observable Markov Decision Process", "node_count": 46, "processed": 2, "reason_for_similarity": "This concept extends the Markov decision process by considering partially observable environments, where the agent does not have full knowledge of the state.", "shape": "dot", "size": 10, "title": "46. \u003ca href=\u0027https://en.wikipedia.org/wiki/Partially_observable_Markov_decision_process\u0027 target=\u0027_blank\u0027\u003ePartially observable Markov decision process\u003c/a\u003e\u003cbr /\u003eA partially observable Markov decision process (POMDP) is a generalization of a Markov decision process (MDP). A POMDP models an agent decision process in which it is assumed that the system dynamics are determined by an MDP, but the agent cannot directly observe the underlying state. Instead, it must maintain a sensor model and the underlying MDP. Unlike the policy function in MDP which maps the underlying states to the actions, POMDP\u0027s policy is a mapping from the history of observations to th\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Partially_observable_Markov_decision_process", "wikipedia_content": "A partially observable Markov decision process (POMDP) is a generalization of a Markov decision process (MDP). A POMDP models an agent decision process in which it is assumed that the system dynamics are determined by an MDP, but the agent cannot directly observe the underlying state. Instead, it must maintain a sensor model and the underlying MDP. Unlike the policy function in MDP which maps the underlying states to the actions, POMDP\u0027s policy is a mapping from the history of observations to th", "wikipedia_link": "https://en.wikipedia.org/wiki/Partially_observable_Markov_decision_process", "wikipedia_normalized": "Partially observable Markov decision process", "wikipedia_resp_code": 200}, {"group": 2, "id": "Reinforcement learning", "label": "Reinforcement learning", "level": 2, "name": "Reinforcement learning", "node_count": 2, "processed": 2, "reason_for_similarity": "Reinforcement learning is a type of machine learning that involves an agent learning to make decisions in an environment to maximize a reward signal. It is inspired by the concept of learning through trial and error, which is also a fundamental aspect of artificial intelligence.", "shape": "dot", "size": 10, "title": "2. \u003ca href=\u0027https://en.wikipedia.org/wiki/Reinforcement_learning\u0027 target=\u0027_blank\u0027\u003eReinforcement learning\u003c/a\u003e\u003cbr /\u003eReinforcement learning (RL) is an area of machine learning concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning.\u003cbr /\u003e[200, G2, L2, PR]", "wikipedia_canonical": "Reinforcement_learning", "wikipedia_content": "Reinforcement learning (RL) is an area of machine learning concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning.", "wikipedia_link": "https://en.wikipedia.org/wiki/Reinforcement_learning", "wikipedia_normalized": "Reinforcement learning", "wikipedia_resp_code": 200}, {"group": 4, "id": "Hidden Markov model", "label": "Hidden Markov model", "level": 4, "name": "Hidden Markov Models (HMM)", "node_count": 61, "processed": 2, "reason_for_similarity": "HMMs are commonly used in speech recognition systems to model the temporal dependencies in speech signals.", "shape": "dot", "size": 10, "title": "61. \u003ca href=\u0027https://en.wikipedia.org/wiki/Hidden_Markov_model\u0027 target=\u0027_blank\u0027\u003eHidden Markov model\u003c/a\u003e\u003cbr /\u003eA hidden Markov model (HMM) is a statistical Markov model in which the system being modeled is assumed to be a Markov process with unobservable (\"hidden\") states. As part of the definition, HMM requires that there be an observable process  whose outcomes are \"influenced\" by the outcomes of  in a known way. Since  cannot be observed directly, the goal is to learn about  by observing  HMM has an additional requirement that the outcome of  at time  must be \"influenced\" exclusively by the outcome of\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Hidden_Markov_model", "wikipedia_content": "A hidden Markov model (HMM) is a statistical Markov model in which the system being modeled is assumed to be a Markov process with unobservable (\"hidden\") states. As part of the definition, HMM requires that there be an observable process  whose outcomes are \"influenced\" by the outcomes of  in a known way. Since  cannot be observed directly, the goal is to learn about  by observing  HMM has an additional requirement that the outcome of  at time  must be \"influenced\" exclusively by the outcome of", "wikipedia_link": "https://en.wikipedia.org/wiki/Hidden_Markov_model", "wikipedia_normalized": "Hidden Markov model", "wikipedia_resp_code": 200}, {"group": 3, "id": "Variational autoencoder", "label": "Variational autoencoder", "level": 3, "name": "Variational Autoencoder", "node_count": 25, "processed": 2, "reason_for_similarity": "Both GANs and VAEs are generative models that learn to generate new data samples. VAEs use an encoder-decoder architecture with a latent space representation, similar to GANs.", "shape": "dot", "size": 10, "title": "25. \u003ca href=\u0027https://en.wikipedia.org/wiki/Variational_autoencoder\u0027 target=\u0027_blank\u0027\u003eVariational autoencoder\u003c/a\u003e\u003cbr /\u003eIn machine learning, a variational autoencoder (VAE) is an artificial neural network architecture introduced by Diederik P. Kingma and Max Welling. It is part of the families of probabilistic graphical models and variational Bayesian methods.\u003cbr /\u003e[200, G3, L3, PR]", "wikipedia_canonical": "Variational_autoencoder", "wikipedia_content": "In machine learning, a variational autoencoder (VAE) is an artificial neural network architecture introduced by Diederik P. Kingma and Max Welling. It is part of the families of probabilistic graphical models and variational Bayesian methods.", "wikipedia_link": "https://en.wikipedia.org/wiki/Variational_autoencoder", "wikipedia_normalized": "Variational autoencoder", "wikipedia_resp_code": 200}, {"group": 3, "id": "Restricted Boltzmann machine", "label": "Restricted Boltzmann machine", "level": 3, "name": "Restricted Boltzmann Machine", "node_count": 27, "processed": 2, "reason_for_similarity": "RBMs are generative models that learn a joint probability distribution over visible and hidden units. They can be used to generate new samples by sampling from the learned distribution, similar to GANs.", "shape": "dot", "size": 10, "title": "27. \u003ca href=\u0027https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine\u0027 target=\u0027_blank\u0027\u003eRestricted Boltzmann machine\u003c/a\u003e\u003cbr /\u003eA restricted Boltzmann machine (RBM) is a generative stochastic artificial neural network that can learn a probability distribution over its set of inputs.\u003cbr /\u003e[200, G3, L3, PR]", "wikipedia_canonical": "Restricted_Boltzmann_machine", "wikipedia_content": "A restricted Boltzmann machine (RBM) is a generative stochastic artificial neural network that can learn a probability distribution over its set of inputs.", "wikipedia_link": "https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine", "wikipedia_normalized": "Restricted Boltzmann machine", "wikipedia_resp_code": 200}, {"group": 4, "id": "Latent Dirichlet allocation", "label": "Latent Dirichlet allocation", "level": 4, "name": "Latent Dirichlet Allocation (LDA)", "node_count": 78, "processed": 2, "reason_for_similarity": "Both Variational autoencoder (VAE) and LDA are generative models used for unsupervised learning. They aim to discover latent topics or representations in the input data.", "shape": "dot", "size": 10, "title": "78. \u003ca href=\u0027https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation\u0027 target=\u0027_blank\u0027\u003eLatent Dirichlet allocation\u003c/a\u003e\u003cbr /\u003eIn natural language processing, Latent Dirichlet Allocation (LDA) is a Bayesian network that explains a set of observations through unobserved groups, and each group explains why some parts of the data are similar. The LDA is an example of a Bayesian topic model. In this, observations are collected into documents, and each word\u0027s presence is attributable to one of the document\u0027s topics. Each document will contain a small number of topics.\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Latent_Dirichlet_allocation", "wikipedia_content": "In natural language processing, Latent Dirichlet Allocation (LDA) is a Bayesian network that explains a set of observations through unobserved groups, and each group explains why some parts of the data are similar. The LDA is an example of a Bayesian topic model. In this, observations are collected into documents, and each word\u0027s presence is attributable to one of the document\u0027s topics. Each document will contain a small number of topics.", "wikipedia_link": "https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation", "wikipedia_normalized": "Latent Dirichlet allocation", "wikipedia_resp_code": 200}, {"group": 4, "id": "Boltzmann machine", "label": "Boltzmann machine", "level": 4, "name": "Boltzmann Machine", "node_count": 82, "processed": 2, "reason_for_similarity": "Restricted Boltzmann Machines (RBMs) are a type of Boltzmann machine. RBMs are a simplified version of Boltzmann machines, where the connections between visible and hidden units form a bipartite graph.", "shape": "dot", "size": 10, "title": "82. \u003ca href=\u0027https://en.wikipedia.org/wiki/Boltzmann_machine\u0027 target=\u0027_blank\u0027\u003eBoltzmann machine\u003c/a\u003e\u003cbr /\u003eA Boltzmann machine is a stochastic spin-glass model with an external field, i.e., a Sherrington\u2013Kirkpatrick model, that is a stochastic Ising model. It is a statistical physics technique applied in the context of cognitive science. It is also classified as a Markov random field.\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Boltzmann_machine", "wikipedia_content": "A Boltzmann machine is a stochastic spin-glass model with an external field, i.e., a Sherrington\u2013Kirkpatrick model, that is a stochastic Ising model. It is a statistical physics technique applied in the context of cognitive science. It is also classified as a Markov random field.", "wikipedia_link": "https://en.wikipedia.org/wiki/Boltzmann_machine", "wikipedia_normalized": "Boltzmann machine", "wikipedia_resp_code": 200}, {"group": 4, "id": "Hopfield network", "label": "Hopfield network", "level": 4, "name": "Hopfield Network", "node_count": 81, "processed": 2, "reason_for_similarity": "Hopfield networks and RBMs are both types of energy-based models. They both use the concept of energy to represent the state of the system and update the network\u0027s weights based on minimizing the energy function.", "shape": "dot", "size": 10, "title": "81. \u003ca href=\u0027https://en.wikipedia.org/wiki/Hopfield_network\u0027 target=\u0027_blank\u0027\u003eHopfield network\u003c/a\u003e\u003cbr /\u003eA Hopfield network is a form of recurrent artificial neural network and a type of spin glass system popularised by John Hopfield in 1982 as described by Shun\u0027ichi Amari in 1972 \nand by Little in 1974 based on Ernst Ising\u0027s work with Wilhelm Lenz on the Ising model. Hopfield networks serve as content-addressable (\"associative\") memory systems with binary threshold nodes, or with continuous variables. Hopfield networks also provide a model for understanding human memory.\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Hopfield_network", "wikipedia_content": "A Hopfield network is a form of recurrent artificial neural network and a type of spin glass system popularised by John Hopfield in 1982 as described by Shun\u0027ichi Amari in 1972 \nand by Little in 1974 based on Ernst Ising\u0027s work with Wilhelm Lenz on the Ising model. Hopfield networks serve as content-addressable (\"associative\") memory systems with binary threshold nodes, or with continuous variables. Hopfield networks also provide a model for understanding human memory.", "wikipedia_link": "https://en.wikipedia.org/wiki/Hopfield_network", "wikipedia_normalized": "Hopfield network", "wikipedia_resp_code": 200}, {"group": 3, "id": "Deep Boltzmann machine", "label": "Deep Boltzmann machine", "level": 3, "name": "Deep Boltzmann Machine", "node_count": 26, "processed": 2, "reason_for_similarity": "DBMs are generative models that use a layered architecture of restricted Boltzmann machines. They can generate new samples by sampling from the joint distribution of the visible and hidden units, similar to GANs.", "shape": "dot", "size": 10, "title": "26. \u003ca href=\u0027https://en.wikipedia.org/wiki/Deep_Boltzmann_machine\u0027 target=\u0027_blank\u0027\u003eDeep Boltzmann machine\u003c/a\u003e \u2192 \u003ca href=\u0027https://en.wikipedia.org/wiki/Boltzmann_machine\u0027 target=\u0027_blank\u0027\u003eBoltzmann machine\u003c/a\u003e\u003cbr /\u003eA Boltzmann machine is a stochastic spin-glass model with an external field, i.e., a Sherrington\u2013Kirkpatrick model, that is a stochastic Ising model. It is a statistical physics technique applied in the context of cognitive science. It is also classified as a Markov random field.\u003cbr /\u003e[200, G3, L3, PR]", "wikipedia_canonical": "Boltzmann_machine", "wikipedia_content": "A Boltzmann machine is a stochastic spin-glass model with an external field, i.e., a Sherrington\u2013Kirkpatrick model, that is a stochastic Ising model. It is a statistical physics technique applied in the context of cognitive science. It is also classified as a Markov random field.", "wikipedia_link": "https://en.wikipedia.org/wiki/Deep_Boltzmann_machine", "wikipedia_normalized": "Boltzmann machine", "wikipedia_resp_code": 200}, {"group": 4, "id": "Object recognition", "label": "Object recognition", "level": 4, "name": "Object recognition", "node_count": 71, "processed": 2, "reason_for_similarity": "Object recognition is a broader concept that encompasses object detection and involves identifying and classifying objects in images or videos.", "shape": "dot", "size": 10, "title": "71. \u003ca href=\u0027https://en.wikipedia.org/wiki/Object_recognition\u0027 target=\u0027_blank\u0027\u003eObject recognition\u003c/a\u003e \u2192 \u003ca href=\u0027https://en.wikipedia.org/wiki/Outline_of_object_recognition\u0027 target=\u0027_blank\u0027\u003eOutline of object recognition\u003c/a\u003e\u003cbr /\u003eObject recognition \u2013 technology in the field of computer vision for finding and identifying objects in an image or video sequence. Humans recognize a multitude of objects in images with little effort, despite the fact that the image of the objects may vary somewhat in different view points, in many different sizes and scales or even when they are translated or rotated. Objects can even be recognized when they are partially obstructed from view. This task is still a challenge for computer vision \u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Outline_of_object_recognition", "wikipedia_content": "Object recognition \u2013 technology in the field of computer vision for finding and identifying objects in an image or video sequence. Humans recognize a multitude of objects in images with little effort, despite the fact that the image of the objects may vary somewhat in different view points, in many different sizes and scales or even when they are translated or rotated. Objects can even be recognized when they are partially obstructed from view. This task is still a challenge for computer vision ", "wikipedia_link": "https://en.wikipedia.org/wiki/Object_recognition", "wikipedia_normalized": "Outline of object recognition", "wikipedia_resp_code": 200}, {"group": 4, "id": "Object tracking", "label": "Object tracking", "level": 4, "name": "Object tracking", "node_count": 72, "processed": 2, "reason_for_similarity": "Object tracking involves following the movement of objects over time, which can be useful in scenarios where object detection needs to be performed continuously.", "shape": "dot", "size": 10, "title": "72. \u003ca href=\u0027https://en.wikipedia.org/wiki/Object_tracking\u0027 target=\u0027_blank\u0027\u003eObject tracking\u003c/a\u003e \u2192 \u003ca href=\u0027https://en.wikipedia.org/wiki/Tracking\u0027 target=\u0027_blank\u0027\u003eTracking\u003c/a\u003e\u003cbr /\u003eTracking may refer to:\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Tracking", "wikipedia_content": "Tracking may refer to:", "wikipedia_link": "https://en.wikipedia.org/wiki/Object_tracking", "wikipedia_normalized": "Tracking", "wikipedia_resp_code": 200}, {"group": 1, "id": "Artificial intelligence", "label": "Artificial intelligence", "level": 1, "name": "Artificial intelligence", "node_count": 0, "processed": 2, "shape": "dot", "size": 10, "title": "0. \u003ca href=\u0027https://en.wikipedia.org/wiki/Artificial_intelligence\u0027 target=\u0027_blank\u0027\u003eArtificial intelligence\u003c/a\u003e\u003cbr /\u003eArtificial intelligence (AI) is the intelligence of machines or software, as opposed to the intelligence of humans or animals. It is also the field of study in computer science that develops and studies intelligent machines. \"AI\" may also refer to the machines themselves.\u003cbr /\u003e[200, G1, L1, PR]", "wikipedia_canonical": "Artificial_intelligence", "wikipedia_content": "Artificial intelligence (AI) is the intelligence of machines or software, as opposed to the intelligence of humans or animals. It is also the field of study in computer science that develops and studies intelligent machines. \"AI\" may also refer to the machines themselves.", "wikipedia_link": "https://en.wikipedia.org/wiki/Artificial_intelligence", "wikipedia_normalized": "Artificial intelligence", "wikipedia_resp_code": 200}, {"group": 2, "id": "Deep learning", "label": "Deep learning", "level": 2, "name": "Deep learning", "node_count": 1, "processed": 2, "reason_for_similarity": "Deep learning is a subfield of artificial intelligence that focuses on the development of neural networks and algorithms inspired by the structure and function of the human brain. It aims to enable machines to learn and make decisions in a way similar to humans, which aligns with the goals of artificial intelligence.", "shape": "dot", "size": 10, "title": "1. \u003ca href=\u0027https://en.wikipedia.org/wiki/Deep_learning\u0027 target=\u0027_blank\u0027\u003eDeep learning\u003c/a\u003e\u003cbr /\u003eDeep learning is part of a broader family of machine learning methods, which is based on artificial neural networks with representation learning. The adjective \"deep\" in deep learning refers to the use of multiple layers in the network. Methods used can be either supervised, semi-supervised or unsupervised.\u003cbr /\u003e[200, G2, L2, PR]", "wikipedia_canonical": "Deep_learning", "wikipedia_content": "Deep learning is part of a broader family of machine learning methods, which is based on artificial neural networks with representation learning. The adjective \"deep\" in deep learning refers to the use of multiple layers in the network. Methods used can be either supervised, semi-supervised or unsupervised.", "wikipedia_link": "https://en.wikipedia.org/wiki/Deep_learning", "wikipedia_normalized": "Deep learning", "wikipedia_resp_code": 200}, {"group": 2, "id": "Natural language processing", "label": "Natural language processing", "level": 2, "name": "Natural language processing", "node_count": 3, "processed": 2, "reason_for_similarity": "Natural language processing (NLP) is a field of study that focuses on the interaction between computers and human language. It involves developing algorithms and models that enable machines to understand, interpret, and generate human language, which is a key aspect of artificial intelligence.", "shape": "dot", "size": 10, "title": "3. \u003ca href=\u0027https://en.wikipedia.org/wiki/Natural_language_processing\u0027 target=\u0027_blank\u0027\u003eNatural language processing\u003c/a\u003e\u003cbr /\u003eNatural language processing (NLP) is an interdisciplinary subfield of computer science and linguistics. It is primarily concerned with giving computers the ability to support and manipulate speech. It involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic machine learning approaches. The goal is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them. The\u003cbr /\u003e[200, G2, L2, PR]", "wikipedia_canonical": "Natural_language_processing", "wikipedia_content": "Natural language processing (NLP) is an interdisciplinary subfield of computer science and linguistics. It is primarily concerned with giving computers the ability to support and manipulate speech. It involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic machine learning approaches. The goal is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them. The", "wikipedia_link": "https://en.wikipedia.org/wiki/Natural_language_processing", "wikipedia_normalized": "Natural language processing", "wikipedia_resp_code": 200}, {"group": 2, "id": "Computer vision", "label": "Computer vision", "level": 2, "name": "Computer vision", "node_count": 4, "processed": 2, "reason_for_similarity": "Computer vision is a subfield of artificial intelligence that deals with enabling computers to gain high-level understanding from digital images or videos. It involves developing algorithms and models that allow machines to perceive and interpret visual information, similar to how humans process visual data.", "shape": "dot", "size": 10, "title": "4. \u003ca href=\u0027https://en.wikipedia.org/wiki/Computer_vision\u0027 target=\u0027_blank\u0027\u003eComputer vision\u003c/a\u003e\u003cbr /\u003eComputer vision tasks include methods for acquiring, processing, analyzing and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information, e.g. in the forms of decisions. Understanding in this context means the transformation of visual images into descriptions of the world that make sense to thought processes and can elicit appropriate action. This image understanding can be seen as the disentangling of symbolic\u003cbr /\u003e[200, G2, L2, PR]", "wikipedia_canonical": "Computer_vision", "wikipedia_content": "Computer vision tasks include methods for acquiring, processing, analyzing and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information, e.g. in the forms of decisions. Understanding in this context means the transformation of visual images into descriptions of the world that make sense to thought processes and can elicit appropriate action. This image understanding can be seen as the disentangling of symbolic", "wikipedia_link": "https://en.wikipedia.org/wiki/Computer_vision", "wikipedia_normalized": "Computer vision", "wikipedia_resp_code": 200}, {"group": 4, "id": "Topic model", "label": "Topic model", "level": 4, "name": "Topic modeling", "node_count": 54, "processed": 2, "reason_for_similarity": "Both involve discovering latent topics in text data", "shape": "dot", "size": 10, "title": "54. \u003ca href=\u0027https://en.wikipedia.org/wiki/Topic_model\u0027 target=\u0027_blank\u0027\u003eTopic model\u003c/a\u003e\u003cbr /\u003eIn statistics and natural language processing, a topic model is a type of statistical model for discovering the abstract \"topics\" that occur in a collection of documents. Topic modeling is a frequently used text-mining tool for discovery of hidden semantic structures in a text body. Intuitively, given that a document is about a particular topic, one would expect particular words to appear in the document more or less frequently: \"dog\" and \"bone\" will appear more often in documents about dogs, \"c\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Topic_model", "wikipedia_content": "In statistics and natural language processing, a topic model is a type of statistical model for discovering the abstract \"topics\" that occur in a collection of documents. Topic modeling is a frequently used text-mining tool for discovery of hidden semantic structures in a text body. Intuitively, given that a document is about a particular topic, one would expect particular words to appear in the document more or less frequently: \"dog\" and \"bone\" will appear more often in documents about dogs, \"c", "wikipedia_link": "https://en.wikipedia.org/wiki/Topic_model", "wikipedia_normalized": "Topic model", "wikipedia_resp_code": 200}, {"group": 4, "id": "Pattern recognition", "label": "Pattern recognition", "level": 4, "name": "Pattern recognition", "node_count": 70, "processed": 2, "reason_for_similarity": "Both involve identifying patterns in data", "shape": "dot", "size": 10, "title": "70. \u003ca href=\u0027https://en.wikipedia.org/wiki/Pattern_recognition\u0027 target=\u0027_blank\u0027\u003ePattern recognition\u003c/a\u003e\u003cbr /\u003ePattern recognition is the automated recognition of patterns and regularities in data. While similar, pattern recognition (PR) is not to be confused with pattern machines (PM) which may possess (PR) capabilities but their primary function is to distinguish and create emergent pattern. PR has applications in statistical data analysis, signal processing, image analysis, information retrieval, bioinformatics, data compression, computer graphics and machine learning. Pattern recognition has its orig\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Pattern_recognition", "wikipedia_content": "Pattern recognition is the automated recognition of patterns and regularities in data. While similar, pattern recognition (PR) is not to be confused with pattern machines (PM) which may possess (PR) capabilities but their primary function is to distinguish and create emergent pattern. PR has applications in statistical data analysis, signal processing, image analysis, information retrieval, bioinformatics, data compression, computer graphics and machine learning. Pattern recognition has its orig", "wikipedia_link": "https://en.wikipedia.org/wiki/Pattern_recognition", "wikipedia_normalized": "Pattern recognition", "wikipedia_resp_code": 200}, {"group": 500, "id": "Scene understanding", "label": "Scene understanding", "level": 4, "name": "Scene understanding", "node_count": 73, "processed": 2, "reason_for_similarity": "Both semantic segmentation and scene understanding aim to comprehend the content and structure of a scene. However, scene understanding involves a broader context, including object relationships, scene layout, and higher-level understanding.", "shape": "dot", "size": 10, "title": "73. \u003ca href=\u0027https://en.wikipedia.org/wiki/Scene_understanding\u0027 target=\u0027_blank\u0027\u003eScene understanding\u003c/a\u003e\u003cbr /\u003e\u003cbr /\u003e[404, G500, L4, PR]", "wikipedia_canonical": "", "wikipedia_content": "", "wikipedia_link": "https://en.wikipedia.org/wiki/Scene_understanding", "wikipedia_normalized": "", "wikipedia_resp_code": 404}, {"group": 500, "id": "Sequence model", "label": "Sequence model", "level": 4, "name": "Sequence Modeling", "node_count": 35, "processed": 2, "reason_for_similarity": "LSTM is commonly used for sequence modeling tasks, such as natural language processing and speech recognition.", "shape": "dot", "size": 10, "title": "35. \u003ca href=\u0027https://en.wikipedia.org/wiki/Sequence_model\u0027 target=\u0027_blank\u0027\u003eSequence model\u003c/a\u003e\u003cbr /\u003e\u003cbr /\u003e[404, G500, L4, PR]", "wikipedia_canonical": "", "wikipedia_content": "", "wikipedia_link": "https://en.wikipedia.org/wiki/Sequence_model", "wikipedia_normalized": "", "wikipedia_resp_code": 404}, {"group": 4, "id": "Cluster analysis", "label": "Cluster analysis", "level": 4, "name": "Clustering", "node_count": 41, "processed": 2, "reason_for_similarity": "Both unsupervised learning and clustering involve finding patterns or groups in data without the use of labeled examples.", "shape": "dot", "size": 10, "title": "41. \u003ca href=\u0027https://en.wikipedia.org/wiki/Cluster_analysis\u0027 target=\u0027_blank\u0027\u003eCluster analysis\u003c/a\u003e\u003cbr /\u003eCluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group are more similar to each other than to those in other groups (clusters). It is a main task of exploratory data analysis, and a common technique for statistical data analysis, used in many fields, including pattern recognition, image analysis, information retrieval, bioinformatics, data compression, computer graphics and machine learning.\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Cluster_analysis", "wikipedia_content": "Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group are more similar to each other than to those in other groups (clusters). It is a main task of exploratory data analysis, and a common technique for statistical data analysis, used in many fields, including pattern recognition, image analysis, information retrieval, bioinformatics, data compression, computer graphics and machine learning.", "wikipedia_link": "https://en.wikipedia.org/wiki/Cluster_analysis", "wikipedia_normalized": "Cluster analysis", "wikipedia_resp_code": 200}, {"group": 4, "id": "Self-organizing map", "label": "Self-organizing map", "level": 4, "name": "Self-organizing maps", "node_count": 45, "processed": 2, "reason_for_similarity": "Both unsupervised learning and self-organizing maps involve organizing and visualizing high-dimensional data in a lower-dimensional space.", "shape": "dot", "size": 10, "title": "45. \u003ca href=\u0027https://en.wikipedia.org/wiki/Self-organizing_map\u0027 target=\u0027_blank\u0027\u003eSelf-organizing map\u003c/a\u003e\u003cbr /\u003eA self-organizing map (SOM) or self-organizing feature map (SOFM) is an unsupervised machine learning technique used to produce a low-dimensional representation of a higher dimensional data set while preserving the topological structure of the data. For example, a data set with  variables measured in  observations could be represented as clusters of observations with similar values for the variables. These clusters then could be visualized as a two-dimensional \"map\" such that observations in pro\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Self-organizing_map", "wikipedia_content": "A self-organizing map (SOM) or self-organizing feature map (SOFM) is an unsupervised machine learning technique used to produce a low-dimensional representation of a higher dimensional data set while preserving the topological structure of the data. For example, a data set with  variables measured in  observations could be represented as clusters of observations with similar values for the variables. These clusters then could be visualized as a two-dimensional \"map\" such that observations in pro", "wikipedia_link": "https://en.wikipedia.org/wiki/Self-organizing_map", "wikipedia_normalized": "Self-organizing map", "wikipedia_resp_code": 200}, {"group": 3, "id": "Image recognition", "label": "Image recognition", "level": 3, "name": "Image recognition", "node_count": 20, "processed": 2, "reason_for_similarity": "Both computer vision and image recognition deal with analyzing and understanding visual data.", "shape": "dot", "size": 10, "title": "20. \u003ca href=\u0027https://en.wikipedia.org/wiki/Image_recognition\u0027 target=\u0027_blank\u0027\u003eImage recognition\u003c/a\u003e \u2192 \u003ca href=\u0027https://en.wikipedia.org/wiki/Computer_vision\u0027 target=\u0027_blank\u0027\u003eComputer vision\u003c/a\u003e\u003cbr /\u003eComputer vision tasks include methods for acquiring, processing, analyzing and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information, e.g. in the forms of decisions. Understanding in this context means the transformation of visual images into descriptions of the world that make sense to thought processes and can elicit appropriate action. This image understanding can be seen as the disentangling of symbolic\u003cbr /\u003e[200, G3, L3, PR]", "wikipedia_canonical": "Computer_vision", "wikipedia_content": "Computer vision tasks include methods for acquiring, processing, analyzing and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information, e.g. in the forms of decisions. Understanding in this context means the transformation of visual images into descriptions of the world that make sense to thought processes and can elicit appropriate action. This image understanding can be seen as the disentangling of symbolic", "wikipedia_link": "https://en.wikipedia.org/wiki/Image_recognition", "wikipedia_normalized": "Computer vision", "wikipedia_resp_code": 200}, {"group": 500, "id": "Deep generative model", "label": "Deep generative model", "level": 3, "name": "Deep Generative Model", "node_count": 28, "processed": 2, "reason_for_similarity": "Deep generative models encompass various architectures, including GANs, VAEs, and DBMs. They are all capable of generating new data samples by learning the underlying distribution of the training data.", "shape": "dot", "size": 10, "title": "28. \u003ca href=\u0027https://en.wikipedia.org/wiki/Deep_generative_model\u0027 target=\u0027_blank\u0027\u003eDeep generative model\u003c/a\u003e\u003cbr /\u003e\u003cbr /\u003e[404, G500, L3, PR]", "wikipedia_canonical": "", "wikipedia_content": "", "wikipedia_link": "https://en.wikipedia.org/wiki/Deep_generative_model", "wikipedia_normalized": "", "wikipedia_resp_code": 404}, {"group": 4, "id": "Autoencoder#Variational autoencoder (VAE)", "label": "Autoencoder#Variational autoencoder (VAE)", "level": 4, "name": "Variational autoencoder", "node_count": 79, "processed": 2, "reason_for_similarity": "Deep Boltzmann machines and variational autoencoders (VAEs) are both generative models. VAEs use an encoder-decoder architecture to learn a latent representation of the input data. Deep Boltzmann machines also learn a latent representation through the hidden units.", "shape": "dot", "size": 10, "title": "79. \u003ca href=\u0027https://en.wikipedia.org/wiki/Autoencoder#Variational_autoencoder_(VAE)\u0027 target=\u0027_blank\u0027\u003eAutoencoder#Variational autoencoder (VAE)\u003c/a\u003e \u2192 \u003ca href=\u0027https://en.wikipedia.org/wiki/Autoencoder\u0027 target=\u0027_blank\u0027\u003eAutoencoder\u003c/a\u003e\u003cbr /\u003eAn autoencoder is a type of artificial neural network used to learn efficient codings of unlabeled data. An autoencoder learns two functions: an encoding function that transforms the input data, and a decoding function that recreates the input data from the encoded representation. The autoencoder learns an efficient representation (encoding) for a set of data, typically for dimensionality reduction.\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Autoencoder", "wikipedia_content": "An autoencoder is a type of artificial neural network used to learn efficient codings of unlabeled data. An autoencoder learns two functions: an encoding function that transforms the input data, and a decoding function that recreates the input data from the encoded representation. The autoencoder learns an efficient representation (encoding) for a set of data, typically for dimensionality reduction.", "wikipedia_link": "https://en.wikipedia.org/wiki/Autoencoder#Variational_autoencoder_(VAE)", "wikipedia_normalized": "Autoencoder", "wikipedia_resp_code": 200}, {"group": 3, "id": "Video analysis", "label": "Video analysis", "level": 3, "name": "Video analysis", "node_count": 24, "processed": 2, "reason_for_similarity": "Both computer vision and video analysis deal with extracting meaningful information from video data, such as object tracking, activity recognition, and event detection.", "shape": "dot", "size": 10, "title": "24. \u003ca href=\u0027https://en.wikipedia.org/wiki/Video_analysis\u0027 target=\u0027_blank\u0027\u003eVideo analysis\u003c/a\u003e \u2192 \u003ca href=\u0027https://en.wikipedia.org/wiki/Video_content_analysis\u0027 target=\u0027_blank\u0027\u003eVideo content analysis\u003c/a\u003e\u003cbr /\u003eVideo content analysis or video content analytics (VCA), also known as video analysis or video analytics (VA), is the capability of automatically analyzing video to detect and determine temporal and spatial events.\u003cbr /\u003e[200, G3, L3, PR]", "wikipedia_canonical": "Video_content_analysis", "wikipedia_content": "Video content analysis or video content analytics (VCA), also known as video analysis or video analytics (VA), is the capability of automatically analyzing video to detect and determine temporal and spatial events.", "wikipedia_link": "https://en.wikipedia.org/wiki/Video_analysis", "wikipedia_normalized": "Video content analysis", "wikipedia_resp_code": 200}, {"group": 4, "id": "Dimensionality reduction", "label": "Dimensionality reduction", "level": 4, "name": "Dimensionality reduction", "node_count": 42, "processed": 2, "reason_for_similarity": "Both unsupervised learning and dimensionality reduction techniques aim to reduce the complexity of high-dimensional data by extracting meaningful features or representations.", "shape": "dot", "size": 10, "title": "42. \u003ca href=\u0027https://en.wikipedia.org/wiki/Dimensionality_reduction\u0027 target=\u0027_blank\u0027\u003eDimensionality reduction\u003c/a\u003e\u003cbr /\u003eDimensionality reduction, or dimension reduction, is the transformation of data from a high-dimensional space into a low-dimensional space so that the low-dimensional representation retains some meaningful properties of the original data, ideally close to its intrinsic dimension. Working in high-dimensional spaces can be undesirable for many reasons; raw data are often sparse as a consequence of the curse of dimensionality, and analyzing the data is usually computationally intractable. Dimension\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Dimensionality_reduction", "wikipedia_content": "Dimensionality reduction, or dimension reduction, is the transformation of data from a high-dimensional space into a low-dimensional space so that the low-dimensional representation retains some meaningful properties of the original data, ideally close to its intrinsic dimension. Working in high-dimensional spaces can be undesirable for many reasons; raw data are often sparse as a consequence of the curse of dimensionality, and analyzing the data is usually computationally intractable. Dimension", "wikipedia_link": "https://en.wikipedia.org/wiki/Dimensionality_reduction", "wikipedia_normalized": "Dimensionality reduction", "wikipedia_resp_code": 200}, {"group": 3, "id": "Unsupervised learning", "label": "Unsupervised learning", "level": 3, "name": "Unsupervised learning", "node_count": 11, "processed": 2, "reason_for_similarity": "Both reinforcement learning and unsupervised learning involve learning without explicit labels, but in reinforcement learning, the agent learns to maximize rewards based on its interactions with the environment.", "shape": "dot", "size": 10, "title": "11. \u003ca href=\u0027https://en.wikipedia.org/wiki/Unsupervised_learning\u0027 target=\u0027_blank\u0027\u003eUnsupervised learning\u003c/a\u003e\u003cbr /\u003eUnsupervised learning is a paradigm in machine learning where, in contrast to supervised learning and semi-supervised learning, algorithms learn patterns exclusively from unlabeled data.\u003cbr /\u003e[200, G3, L3, PR]", "wikipedia_canonical": "Unsupervised_learning", "wikipedia_content": "Unsupervised learning is a paradigm in machine learning where, in contrast to supervised learning and semi-supervised learning, algorithms learn patterns exclusively from unlabeled data.", "wikipedia_link": "https://en.wikipedia.org/wiki/Unsupervised_learning", "wikipedia_normalized": "Unsupervised learning", "wikipedia_resp_code": 200}, {"group": 4, "id": "Anomaly detection", "label": "Anomaly detection", "level": 4, "name": "Anomaly detection", "node_count": 43, "processed": 2, "reason_for_similarity": "Both unsupervised learning and anomaly detection focus on identifying rare or abnormal instances in a dataset without relying on labeled data.", "shape": "dot", "size": 10, "title": "43. \u003ca href=\u0027https://en.wikipedia.org/wiki/Anomaly_detection\u0027 target=\u0027_blank\u0027\u003eAnomaly detection\u003c/a\u003e\u003cbr /\u003eIn data analysis, anomaly detection is generally understood to be the identification of rare items, events or observations which deviate significantly from the majority of the data and do not conform to a well defined notion of normal behaviour. Such examples may arouse suspicions of being generated by a different mechanism, or appear inconsistent with the remainder of that set of data.\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Anomaly_detection", "wikipedia_content": "In data analysis, anomaly detection is generally understood to be the identification of rare items, events or observations which deviate significantly from the majority of the data and do not conform to a well defined notion of normal behaviour. Such examples may arouse suspicions of being generated by a different mechanism, or appear inconsistent with the remainder of that set of data.", "wikipedia_link": "https://en.wikipedia.org/wiki/Anomaly_detection", "wikipedia_normalized": "Anomaly detection", "wikipedia_resp_code": 200}, {"group": 4, "id": "Generative model", "label": "Generative model", "level": 4, "name": "Generative models", "node_count": 44, "processed": 2, "reason_for_similarity": "Both unsupervised learning and generative models aim to learn the underlying distribution of the data and generate new samples from it.", "shape": "dot", "size": 10, "title": "44. \u003ca href=\u0027https://en.wikipedia.org/wiki/Generative_model\u0027 target=\u0027_blank\u0027\u003eGenerative model\u003c/a\u003e\u003cbr /\u003eIn statistical classification, two main approaches are called the generative approach and the discriminative approach. These compute classifiers by different approaches, differing in the degree of statistical modelling. Terminology is inconsistent, but three major types can be distinguished, following Jebara (2004):A generative model is a statistical model of the joint probability distribution  on given observable variable X and target variable Y;\nA discriminative model is a model of the conditi\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Generative_model", "wikipedia_content": "In statistical classification, two main approaches are called the generative approach and the discriminative approach. These compute classifiers by different approaches, differing in the degree of statistical modelling. Terminology is inconsistent, but three major types can be distinguished, following Jebara (2004):A generative model is a statistical model of the joint probability distribution  on given observable variable X and target variable Y;\nA discriminative model is a model of the conditi", "wikipedia_link": "https://en.wikipedia.org/wiki/Generative_model", "wikipedia_normalized": "Generative model", "wikipedia_resp_code": 200}, {"group": 500, "id": "Instance recognition", "label": "Instance recognition", "level": 4, "name": "Instance recognition", "node_count": 74, "processed": 2, "reason_for_similarity": "Both instance segmentation and instance recognition involve identifying and distinguishing individual instances of objects within an image.", "shape": "dot", "size": 10, "title": "74. \u003ca href=\u0027https://en.wikipedia.org/wiki/Instance_recognition\u0027 target=\u0027_blank\u0027\u003eInstance recognition\u003c/a\u003e\u003cbr /\u003e\u003cbr /\u003e[404, G500, L4, PR]", "wikipedia_canonical": "", "wikipedia_content": "", "wikipedia_link": "https://en.wikipedia.org/wiki/Instance_recognition", "wikipedia_normalized": "", "wikipedia_resp_code": 404}, {"group": 4, "id": "Belief propagation#Deep belief propagation", "label": "Belief propagation#Deep belief propagation", "level": 4, "name": "Deep belief propagation", "node_count": 80, "processed": 2, "reason_for_similarity": "Deep Boltzmann machines and deep belief propagation (DBP) are both deep learning models. DBP extends belief propagation to deep architectures, allowing for inference and learning in deep graphical models. Deep Boltzmann machines are also deep graphical models that can perform inference and learning.", "shape": "dot", "size": 10, "title": "80. \u003ca href=\u0027https://en.wikipedia.org/wiki/Belief_propagation#Deep_belief_propagation\u0027 target=\u0027_blank\u0027\u003eBelief propagation#Deep belief propagation\u003c/a\u003e \u2192 \u003ca href=\u0027https://en.wikipedia.org/wiki/Belief_propagation\u0027 target=\u0027_blank\u0027\u003eBelief propagation\u003c/a\u003e\u003cbr /\u003eBelief propagation, also known as sum\u2013product message passing, is a message-passing algorithm for performing inference on graphical models, such as Bayesian networks and Markov random fields. It calculates the marginal distribution for each unobserved node, conditional on any observed nodes. Belief propagation is commonly used in artificial intelligence and information theory, and has demonstrated empirical success in numerous applications, including low-density parity-check codes, turbo codes, \u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Belief_propagation", "wikipedia_content": "Belief propagation, also known as sum\u2013product message passing, is a message-passing algorithm for performing inference on graphical models, such as Bayesian networks and Markov random fields. It calculates the marginal distribution for each unobserved node, conditional on any observed nodes. Belief propagation is commonly used in artificial intelligence and information theory, and has demonstrated empirical success in numerous applications, including low-density parity-check codes, turbo codes, ", "wikipedia_link": "https://en.wikipedia.org/wiki/Belief_propagation#Deep_belief_propagation", "wikipedia_normalized": "Belief propagation", "wikipedia_resp_code": 200}, {"group": 4, "id": "Dynamic programming", "label": "Dynamic programming", "level": 4, "name": "Dynamic Programming", "node_count": 47, "processed": 2, "reason_for_similarity": "Both Markov decision process and dynamic programming involve solving optimization problems by breaking them down into smaller subproblems and using the principle of optimality.", "shape": "dot", "size": 10, "title": "47. \u003ca href=\u0027https://en.wikipedia.org/wiki/Dynamic_programming\u0027 target=\u0027_blank\u0027\u003eDynamic programming\u003c/a\u003e\u003cbr /\u003eDynamic programming is both a mathematical optimization method and an algorithmic paradigm. The method was developed by Richard Bellman in the 1950s and has found applications in numerous fields, from aerospace engineering to economics.\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Dynamic_programming", "wikipedia_content": "Dynamic programming is both a mathematical optimization method and an algorithmic paradigm. The method was developed by Richard Bellman in the 1950s and has found applications in numerous fields, from aerospace engineering to economics.", "wikipedia_link": "https://en.wikipedia.org/wiki/Dynamic_programming", "wikipedia_normalized": "Dynamic programming", "wikipedia_resp_code": 200}, {"group": 3, "id": "Markov decision process", "label": "Markov decision process", "level": 3, "name": "Markov decision process", "node_count": 12, "processed": 2, "reason_for_similarity": "Reinforcement learning is often formulated as a Markov decision process (MDP), where the agent takes actions in an environment based on its current state and receives rewards or punishments.", "shape": "dot", "size": 10, "title": "12. \u003ca href=\u0027https://en.wikipedia.org/wiki/Markov_decision_process\u0027 target=\u0027_blank\u0027\u003eMarkov decision process\u003c/a\u003e\u003cbr /\u003eIn mathematics, a Markov decision process (MDP) is a discrete-time stochastic control process. It provides a mathematical framework for modeling decision making in situations where outcomes are partly random and partly under the control of a decision maker. MDPs are useful for studying optimization problems solved via dynamic programming. MDPs were known at least as early as the 1950s; a core body of research on Markov decision processes resulted from Ronald Howard\u0027s 1960 book, Dynamic Programmi\u003cbr /\u003e[200, G3, L3, PR]", "wikipedia_canonical": "Markov_decision_process", "wikipedia_content": "In mathematics, a Markov decision process (MDP) is a discrete-time stochastic control process. It provides a mathematical framework for modeling decision making in situations where outcomes are partly random and partly under the control of a decision maker. MDPs are useful for studying optimization problems solved via dynamic programming. MDPs were known at least as early as the 1950s; a core body of research on Markov decision processes resulted from Ronald Howard\u0027s 1960 book, Dynamic Programmi", "wikipedia_link": "https://en.wikipedia.org/wiki/Markov_decision_process", "wikipedia_normalized": "Markov decision process", "wikipedia_resp_code": 200}, {"group": 500, "id": "Temporal dependency", "label": "Temporal dependency", "level": 4, "name": "Temporal Dependency Modeling", "node_count": 36, "processed": 2, "reason_for_similarity": "LSTM is specifically designed to model temporal dependencies in sequential data, making it similar to other techniques used for temporal dependency modeling.", "shape": "dot", "size": 10, "title": "36. \u003ca href=\u0027https://en.wikipedia.org/wiki/Temporal_dependency\u0027 target=\u0027_blank\u0027\u003eTemporal dependency\u003c/a\u003e\u003cbr /\u003e\u003cbr /\u003e[404, G500, L4, PR]", "wikipedia_canonical": "", "wikipedia_content": "", "wikipedia_link": "https://en.wikipedia.org/wiki/Temporal_dependency", "wikipedia_normalized": "", "wikipedia_resp_code": 404}, {"group": 4, "id": "Action recognition", "label": "Action recognition", "level": 4, "name": "Action recognition", "node_count": 75, "processed": 2, "reason_for_similarity": "Video analysis often involves recognizing and classifying actions or activities performed in videos, which is the main focus of action recognition.", "shape": "dot", "size": 10, "title": "75. \u003ca href=\u0027https://en.wikipedia.org/wiki/Action_recognition\u0027 target=\u0027_blank\u0027\u003eAction recognition\u003c/a\u003e \u2192 \u003ca href=\u0027https://en.wikipedia.org/wiki/Activity_recognition\u0027 target=\u0027_blank\u0027\u003eActivity recognition\u003c/a\u003e\u003cbr /\u003eActivity recognition aims to recognize the actions and goals of one or more agents from a series of observations on the agents\u0027 actions and the environmental conditions. Since the 1980s, this research field has captured the attention of several computer science communities due to its strength in providing personalized support for many different applications and its connection to many different fields of study such as medicine, human-computer interaction, or sociology.\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Activity_recognition", "wikipedia_content": "Activity recognition aims to recognize the actions and goals of one or more agents from a series of observations on the agents\u0027 actions and the environmental conditions. Since the 1980s, this research field has captured the attention of several computer science communities due to its strength in providing personalized support for many different applications and its connection to many different fields of study such as medicine, human-computer interaction, or sociology.", "wikipedia_link": "https://en.wikipedia.org/wiki/Action_recognition", "wikipedia_normalized": "Activity recognition", "wikipedia_resp_code": 200}, {"group": 3, "id": "Speech recognition", "label": "Speech recognition", "level": 3, "name": "Speech recognition", "node_count": 17, "processed": 2, "reason_for_similarity": "Both involve understanding and processing human language.", "shape": "dot", "size": 10, "title": "17. \u003ca href=\u0027https://en.wikipedia.org/wiki/Speech_recognition\u0027 target=\u0027_blank\u0027\u003eSpeech recognition\u003c/a\u003e\u003cbr /\u003e\nSpeech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methodologies and technologies that enable the recognition and translation of spoken language into text by computers. It is also known as automatic speech recognition (ASR), computer speech recognition or speech to text (STT). It incorporates knowledge and research in the computer science, linguistics and computer engineering fields. The reverse process is speech synthesis.\u003cbr /\u003e[200, G3, L3, PR]", "wikipedia_canonical": "Speech_recognition", "wikipedia_content": "\nSpeech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methodologies and technologies that enable the recognition and translation of spoken language into text by computers. It is also known as automatic speech recognition (ASR), computer speech recognition or speech to text (STT). It incorporates knowledge and research in the computer science, linguistics and computer engineering fields. The reverse process is speech synthesis.", "wikipedia_link": "https://en.wikipedia.org/wiki/Speech_recognition", "wikipedia_normalized": "Speech recognition", "wikipedia_resp_code": 200}, {"group": 4, "id": "Audio signal processing", "label": "Audio signal processing", "level": 4, "name": "Audio Signal Processing", "node_count": 60, "processed": 2, "reason_for_similarity": "Both speech recognition and audio signal processing involve analyzing and processing audio signals.", "shape": "dot", "size": 10, "title": "60. \u003ca href=\u0027https://en.wikipedia.org/wiki/Audio_signal_processing\u0027 target=\u0027_blank\u0027\u003eAudio signal processing\u003c/a\u003e\u003cbr /\u003eAudio signal processing is a subfield of signal processing that is concerned with the electronic manipulation of audio signals. Audio signals are electronic representations of sound waves\u2014longitudinal waves which travel through air, consisting of compressions and rarefactions. The energy contained in audio signals or sound level is typically measured in decibels. As audio signals may be represented in either digital or analog format, processing may occur in either domain. Analog processors opera\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Audio_signal_processing", "wikipedia_content": "Audio signal processing is a subfield of signal processing that is concerned with the electronic manipulation of audio signals. Audio signals are electronic representations of sound waves\u2014longitudinal waves which travel through air, consisting of compressions and rarefactions. The energy contained in audio signals or sound level is typically measured in decibels. As audio signals may be represented in either digital or analog format, processing may occur in either domain. Analog processors opera", "wikipedia_link": "https://en.wikipedia.org/wiki/Audio_signal_processing", "wikipedia_normalized": "Audio signal processing", "wikipedia_resp_code": 200}, {"group": 4, "id": "Automatic speech recognition", "label": "Automatic speech recognition", "level": 4, "name": "Automatic Speech Recognition (ASR)", "node_count": 62, "processed": 2, "reason_for_similarity": "ASR is directly related to speech recognition and focuses on developing algorithms and systems for converting spoken language into written text.", "shape": "dot", "size": 10, "title": "62. \u003ca href=\u0027https://en.wikipedia.org/wiki/Automatic_speech_recognition\u0027 target=\u0027_blank\u0027\u003eAutomatic speech recognition\u003c/a\u003e \u2192 \u003ca href=\u0027https://en.wikipedia.org/wiki/Speech_recognition\u0027 target=\u0027_blank\u0027\u003eSpeech recognition\u003c/a\u003e\u003cbr /\u003e\nSpeech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methodologies and technologies that enable the recognition and translation of spoken language into text by computers. It is also known as automatic speech recognition (ASR), computer speech recognition or speech to text (STT). It incorporates knowledge and research in the computer science, linguistics and computer engineering fields. The reverse process is speech synthesis.\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Speech_recognition", "wikipedia_content": "\nSpeech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methodologies and technologies that enable the recognition and translation of spoken language into text by computers. It is also known as automatic speech recognition (ASR), computer speech recognition or speech to text (STT). It incorporates knowledge and research in the computer science, linguistics and computer engineering fields. The reverse process is speech synthesis.", "wikipedia_link": "https://en.wikipedia.org/wiki/Automatic_speech_recognition", "wikipedia_normalized": "Speech recognition", "wikipedia_resp_code": 200}, {"group": 500, "id": "Policy gradient methods", "label": "Policy gradient methods", "level": 3, "name": "Policy gradient methods", "node_count": 14, "processed": 2, "reason_for_similarity": "Policy gradient methods are a class of reinforcement learning algorithms that directly optimize the policy of an agent to maximize rewards. They share the goal of maximizing rewards with reinforcement learning.", "shape": "dot", "size": 10, "title": "14. \u003ca href=\u0027https://en.wikipedia.org/wiki/Policy_gradient_methods\u0027 target=\u0027_blank\u0027\u003ePolicy gradient methods\u003c/a\u003e\u003cbr /\u003e\u003cbr /\u003e[404, G500, L3, PR]", "wikipedia_canonical": "", "wikipedia_content": "", "wikipedia_link": "https://en.wikipedia.org/wiki/Policy_gradient_methods", "wikipedia_normalized": "", "wikipedia_resp_code": 404}, {"group": 4, "id": "Gradient descent", "label": "Gradient descent", "level": 4, "name": "Gradient Descent", "node_count": 52, "processed": 2, "reason_for_similarity": "Policy gradient methods use gradient descent to update the policy parameters.", "shape": "dot", "size": 10, "title": "52. \u003ca href=\u0027https://en.wikipedia.org/wiki/Gradient_descent\u0027 target=\u0027_blank\u0027\u003eGradient descent\u003c/a\u003e\u003cbr /\u003eIn mathematics, gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. The idea is to take repeated steps in the opposite direction of the gradient of the function at the current point, because this is the direction of steepest descent. Conversely, stepping in the direction of the gradient will lead to a local maximum of that function; the procedure is then known as gradient ascent.\nIt is particularly useful in machine learnin\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Gradient_descent", "wikipedia_content": "In mathematics, gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. The idea is to take repeated steps in the opposite direction of the gradient of the function at the current point, because this is the direction of steepest descent. Conversely, stepping in the direction of the gradient will lead to a local maximum of that function; the procedure is then known as gradient ascent.\nIt is particularly useful in machine learnin", "wikipedia_link": "https://en.wikipedia.org/wiki/Gradient_descent", "wikipedia_normalized": "Gradient descent", "wikipedia_resp_code": 200}, {"group": 4, "id": "Monte Carlo method", "label": "Monte Carlo method", "level": 4, "name": "Monte Carlo Methods", "node_count": 48, "processed": 2, "reason_for_similarity": "Monte Carlo methods can be used to estimate the value function or policy in Markov decision processes by sampling trajectories and averaging the rewards.", "shape": "dot", "size": 10, "title": "48. \u003ca href=\u0027https://en.wikipedia.org/wiki/Monte_Carlo_method\u0027 target=\u0027_blank\u0027\u003eMonte Carlo method\u003c/a\u003e\u003cbr /\u003eMonte Carlo methods, or Monte Carlo experiments, are a broad class of computational algorithms that rely on repeated random sampling to obtain numerical results. The underlying concept is to use randomness to solve problems that might be deterministic in principle. They are often used in physical and mathematical problems and are most useful when it is difficult or impossible to use other approaches. Monte Carlo methods are mainly used in three problem classes: optimization, numerical integratio\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Monte_Carlo_method", "wikipedia_content": "Monte Carlo methods, or Monte Carlo experiments, are a broad class of computational algorithms that rely on repeated random sampling to obtain numerical results. The underlying concept is to use randomness to solve problems that might be deterministic in principle. They are often used in physical and mathematical problems and are most useful when it is difficult or impossible to use other approaches. Monte Carlo methods are mainly used in three problem classes: optimization, numerical integratio", "wikipedia_link": "https://en.wikipedia.org/wiki/Monte_Carlo_method", "wikipedia_normalized": "Monte Carlo method", "wikipedia_resp_code": 200}, {"group": 4, "id": "Actor\u2013critic method", "label": "Actor\u2013critic method", "level": 4, "name": "Actor-Critic Methods", "node_count": 53, "processed": 2, "reason_for_similarity": "Policy gradient methods can be considered as a type of actor-critic method, where the policy is updated based on the estimated value function.", "shape": "dot", "size": 10, "title": "53. \u003ca href=\u0027https://en.wikipedia.org/wiki/Actor%E2%80%93critic_method\u0027 target=\u0027_blank\u0027\u003eActor\u2013critic method\u003c/a\u003e \u2192 \u003ca href=\u0027https://en.wikipedia.org/wiki/Reinforcement_learning\u0027 target=\u0027_blank\u0027\u003eReinforcement learning\u003c/a\u003e\u003cbr /\u003eReinforcement learning (RL) is an area of machine learning concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning.\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Reinforcement_learning", "wikipedia_content": "Reinforcement learning (RL) is an area of machine learning concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning.", "wikipedia_link": "https://en.wikipedia.org/wiki/Actor%E2%80%93critic_method", "wikipedia_normalized": "Reinforcement learning", "wikipedia_resp_code": 200}, {"group": 3, "id": "Named-entity recognition", "label": "Named-entity recognition", "level": 3, "name": "Named entity recognition", "node_count": 18, "processed": 2, "reason_for_similarity": "Both involve identifying and classifying named entities in text.", "shape": "dot", "size": 10, "title": "18. \u003ca href=\u0027https://en.wikipedia.org/wiki/Named-entity_recognition\u0027 target=\u0027_blank\u0027\u003eNamed-entity recognition\u003c/a\u003e\u003cbr /\u003eNamed-entity recognition (NER) (also known as (named) entity identification, entity chunking, and entity extraction) is a subtask of information extraction that seeks to locate and classify named entities mentioned in unstructured text into pre-defined categories such as person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages, etc.\u003cbr /\u003e[200, G3, L3, PR]", "wikipedia_canonical": "Named-entity_recognition", "wikipedia_content": "Named-entity recognition (NER) (also known as (named) entity identification, entity chunking, and entity extraction) is a subtask of information extraction that seeks to locate and classify named entities mentioned in unstructured text into pre-defined categories such as person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages, etc.", "wikipedia_link": "https://en.wikipedia.org/wiki/Named-entity_recognition", "wikipedia_normalized": "Named-entity recognition", "wikipedia_resp_code": 200}, {"group": 4, "id": "Coreference resolution", "label": "Coreference resolution", "level": 4, "name": "Coreference resolution", "node_count": 65, "processed": 2, "reason_for_similarity": "Both Named-entity recognition and Coreference resolution deal with understanding references in text, with Named-entity recognition focusing on identifying specific named entities.", "shape": "dot", "size": 10, "title": "65. \u003ca href=\u0027https://en.wikipedia.org/wiki/Coreference_resolution\u0027 target=\u0027_blank\u0027\u003eCoreference resolution\u003c/a\u003e \u2192 \u003ca href=\u0027https://en.wikipedia.org/wiki/Coreference\u0027 target=\u0027_blank\u0027\u003eCoreference\u003c/a\u003e\u003cbr /\u003eIn linguistics, coreference, sometimes written co-reference, occurs when two or more expressions refer to the same person or thing; they have the same referent. For example, in Bill said Alice would arrive soon, and she did, the words Alice and she refer to the same person.\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Coreference", "wikipedia_content": "In linguistics, coreference, sometimes written co-reference, occurs when two or more expressions refer to the same person or thing; they have the same referent. For example, in Bill said Alice would arrive soon, and she did, the words Alice and she refer to the same person.", "wikipedia_link": "https://en.wikipedia.org/wiki/Coreference_resolution", "wikipedia_normalized": "Coreference", "wikipedia_resp_code": 200}, {"group": 3, "id": "Supervised learning", "label": "Supervised learning", "level": 3, "name": "Supervised learning", "node_count": 10, "processed": 2, "reason_for_similarity": "Both reinforcement learning and supervised learning involve learning from labeled data, but in reinforcement learning, the agent learns from feedback in the form of rewards or punishments.", "shape": "dot", "size": 10, "title": "10. \u003ca href=\u0027https://en.wikipedia.org/wiki/Supervised_learning\u0027 target=\u0027_blank\u0027\u003eSupervised learning\u003c/a\u003e\u003cbr /\u003eSupervised learning (SL) is a paradigm in machine learning where input objects and a desired output value train a model. The training data is processed, building a function that maps new data on expected output values. An optimal scenario will allow for the algorithm to correctly determine output values for unseen instances. This requires the learning algorithm to generalize from the training data to unseen situations in a \"reasonable\" way. This statistical quality of an algorithm is measured th\u003cbr /\u003e[200, G3, L3, PR]", "wikipedia_canonical": "Supervised_learning", "wikipedia_content": "Supervised learning (SL) is a paradigm in machine learning where input objects and a desired output value train a model. The training data is processed, building a function that maps new data on expected output values. An optimal scenario will allow for the algorithm to correctly determine output values for unseen instances. This requires the learning algorithm to generalize from the training data to unseen situations in a \"reasonable\" way. This statistical quality of an algorithm is measured th", "wikipedia_link": "https://en.wikipedia.org/wiki/Supervised_learning", "wikipedia_normalized": "Supervised learning", "wikipedia_resp_code": 200}, {"group": 4, "id": "Active learning (machine learning)", "label": "Active learning (machine learning)", "level": 4, "name": "Active learning", "node_count": 40, "processed": 2, "reason_for_similarity": "Active learning is a learning paradigm where a model actively selects the most informative data points to be labeled by an oracle. This selection process is based on the model\u0027s current knowledge. In supervised learning, the model learns from labeled examples, but in active learning, the model actively participates in the labeling process, similar to how it actively selects data points for labeling.", "shape": "dot", "size": 10, "title": "40. \u003ca href=\u0027https://en.wikipedia.org/wiki/Active_learning_(machine_learning)\u0027 target=\u0027_blank\u0027\u003eActive learning (machine learning)\u003c/a\u003e\u003cbr /\u003eActive learning is a special case of machine learning in which a learning algorithm can interactively query a user to label new data points with the desired outputs. In statistics literature, it is sometimes also called optimal experimental design. The information source is also called teacher or oracle.\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Active_learning_(machine_learning)", "wikipedia_content": "Active learning is a special case of machine learning in which a learning algorithm can interactively query a user to label new data points with the desired outputs. In statistics literature, it is sometimes also called optimal experimental design. The information source is also called teacher or oracle.", "wikipedia_link": "https://en.wikipedia.org/wiki/Active_learning_(machine_learning)", "wikipedia_normalized": "Active learning (machine learning)", "wikipedia_resp_code": 200}, {"group": 4, "id": "Semi-supervised learning", "label": "Semi-supervised learning", "level": 4, "name": "Semi-supervised learning", "node_count": 38, "processed": 2, "reason_for_similarity": "Semi-supervised learning is similar to supervised learning as it also deals with labeled data. However, in semi-supervised learning, the training data consists of both labeled and unlabeled examples. This makes it a combination of supervised and unsupervised learning.", "shape": "dot", "size": 10, "title": "38. \u003ca href=\u0027https://en.wikipedia.org/wiki/Semi-supervised_learning\u0027 target=\u0027_blank\u0027\u003eSemi-supervised learning\u003c/a\u003e \u2192 \u003ca href=\u0027https://en.wikipedia.org/wiki/Weak_supervision\u0027 target=\u0027_blank\u0027\u003eWeak supervision\u003c/a\u003e\u003cbr /\u003eWeak supervision, also called semi-supervised learning, is a paradigm in machine learning, the relevance and notability of which increased with the advent of large language models due to large amount of data required to train them. It is characterized by using a combination of a small amount of human-labeled data, followed by a large amount of unlabeled data. In other words, the desired output values are provided only for a subset of the training data. The remaining data is unlabeled or imprecis\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Weak_supervision", "wikipedia_content": "Weak supervision, also called semi-supervised learning, is a paradigm in machine learning, the relevance and notability of which increased with the advent of large language models due to large amount of data required to train them. It is characterized by using a combination of a small amount of human-labeled data, followed by a large amount of unlabeled data. In other words, the desired output values are provided only for a subset of the training data. The remaining data is unlabeled or imprecis", "wikipedia_link": "https://en.wikipedia.org/wiki/Semi-supervised_learning", "wikipedia_normalized": "Weak supervision", "wikipedia_resp_code": 200}, {"group": 4, "id": "Transfer learning", "label": "Transfer learning", "level": 4, "name": "Transfer learning", "node_count": 39, "processed": 2, "reason_for_similarity": "Transfer learning is a technique where knowledge gained from solving one problem is applied to a different but related problem. Similarly, in supervised learning, models are trained on labeled data to make predictions. Transfer learning can be seen as a way to transfer the knowledge gained from one supervised learning task to another.", "shape": "dot", "size": 10, "title": "39. \u003ca href=\u0027https://en.wikipedia.org/wiki/Transfer_learning\u0027 target=\u0027_blank\u0027\u003eTransfer learning\u003c/a\u003e\u003cbr /\u003eTransfer learning (TL) is a technique in machine learning (ML) in which knowledge learned from a task is re-used in order to boost performance on a related task. For example, for image classification, knowledge gained while learning to recognize cars could be applied when trying to recognize trucks. This topic is related to the psychological literature on transfer of learning, although practical ties between the two fields are limited. Reusing/transferring information from previously learned tas\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Transfer_learning", "wikipedia_content": "Transfer learning (TL) is a technique in machine learning (ML) in which knowledge learned from a task is re-used in order to boost performance on a related task. For example, for image classification, knowledge gained while learning to recognize cars could be applied when trying to recognize trucks. This topic is related to the psychological literature on transfer of learning, although practical ties between the two fields are limited. Reusing/transferring information from previously learned tas", "wikipedia_link": "https://en.wikipedia.org/wiki/Transfer_learning", "wikipedia_normalized": "Transfer learning", "wikipedia_resp_code": 200}, {"group": 4, "id": "Opinion mining", "label": "Opinion mining", "level": 4, "name": "Opinion mining", "node_count": 66, "processed": 2, "reason_for_similarity": "Both sentiment analysis and opinion mining aim to extract subjective information from text.", "shape": "dot", "size": 10, "title": "66. \u003ca href=\u0027https://en.wikipedia.org/wiki/Opinion_mining\u0027 target=\u0027_blank\u0027\u003eOpinion mining\u003c/a\u003e \u2192 \u003ca href=\u0027https://en.wikipedia.org/wiki/Sentiment_analysis\u0027 target=\u0027_blank\u0027\u003eSentiment analysis\u003c/a\u003e\u003cbr /\u003e\nSentiment analysis is the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information. Sentiment analysis is widely applied to voice of the customer materials such as reviews and survey responses, online and social media, and healthcare materials for applications that range from marketing to customer service to clinical medicine. With the rise of deep language mo\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Sentiment_analysis", "wikipedia_content": "\nSentiment analysis is the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information. Sentiment analysis is widely applied to voice of the customer materials such as reviews and survey responses, online and social media, and healthcare materials for applications that range from marketing to customer service to clinical medicine. With the rise of deep language mo", "wikipedia_link": "https://en.wikipedia.org/wiki/Opinion_mining", "wikipedia_normalized": "Sentiment analysis", "wikipedia_resp_code": 200}, {"group": 4, "id": "Emotion recognition", "label": "Emotion recognition", "level": 4, "name": "Emotion recognition", "node_count": 67, "processed": 2, "reason_for_similarity": "Sentiment analysis involves detecting and understanding emotions expressed in text, similar to emotion recognition.", "shape": "dot", "size": 10, "title": "67. \u003ca href=\u0027https://en.wikipedia.org/wiki/Emotion_recognition\u0027 target=\u0027_blank\u0027\u003eEmotion recognition\u003c/a\u003e\u003cbr /\u003eEmotion recognition is the process of identifying human emotion. People vary widely in their accuracy at recognizing the emotions of others. Use of technology to help people with emotion recognition is a relatively nascent research area. Generally, the technology works best if it uses multiple modalities in context. To date, the most work has been conducted on automating the recognition of facial expressions from video, spoken expressions from audio, written expressions from text, and physiology\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Emotion_recognition", "wikipedia_content": "Emotion recognition is the process of identifying human emotion. People vary widely in their accuracy at recognizing the emotions of others. Use of technology to help people with emotion recognition is a relatively nascent research area. Generally, the technology works best if it uses multiple modalities in context. To date, the most work has been conducted on automating the recognition of facial expressions from video, spoken expressions from audio, written expressions from text, and physiology", "wikipedia_link": "https://en.wikipedia.org/wiki/Emotion_recognition", "wikipedia_normalized": "Emotion recognition", "wikipedia_resp_code": 200}, {"group": 4, "id": "Social media analysis", "label": "Social media analysis", "level": 4, "name": "Social media analysis", "node_count": 68, "processed": 2, "reason_for_similarity": "Sentiment analysis is commonly used in social media analysis to understand public opinion and sentiment.", "shape": "dot", "size": 10, "title": "68. \u003ca href=\u0027https://en.wikipedia.org/wiki/Social_media_analysis\u0027 target=\u0027_blank\u0027\u003eSocial media analysis\u003c/a\u003e \u2192 \u003ca href=\u0027https://en.wikipedia.org/wiki/Social_media_analytics\u0027 target=\u0027_blank\u0027\u003eSocial media analytics\u003c/a\u003e\u003cbr /\u003eSocial media analytics is the process of gathering and analyzing data from social networks. It is commonly used by marketers to track online conversations about products and companies. One author defined it as \"the art and science of extracting valuable hidden insights from vast amounts of semi-structured and unstructured social media data to enable informed and insightful decision making.\"\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Social_media_analytics", "wikipedia_content": "Social media analytics is the process of gathering and analyzing data from social networks. It is commonly used by marketers to track online conversations about products and companies. One author defined it as \"the art and science of extracting valuable hidden insights from vast amounts of semi-structured and unstructured social media data to enable informed and insightful decision making.\"", "wikipedia_link": "https://en.wikipedia.org/wiki/Social_media_analysis", "wikipedia_normalized": "Social media analytics", "wikipedia_resp_code": 200}, {"group": 500, "id": "Deep Q-Networks", "label": "Deep Q-Networks", "level": 4, "name": "Deep Q-Networks (DQN)", "node_count": 50, "processed": 2, "reason_for_similarity": "DQN is an extension of Q-learning that uses deep neural networks to approximate the action-value function. Both Q-learning and DQN aim to learn optimal policies through value iteration.", "shape": "dot", "size": 10, "title": "50. \u003ca href=\u0027https://en.wikipedia.org/wiki/Deep_Q-Networks\u0027 target=\u0027_blank\u0027\u003eDeep Q-Networks\u003c/a\u003e\u003cbr /\u003e\u003cbr /\u003e[404, G500, L4, PR]", "wikipedia_canonical": "", "wikipedia_content": "", "wikipedia_link": "https://en.wikipedia.org/wiki/Deep_Q-Networks", "wikipedia_normalized": "", "wikipedia_resp_code": 404}, {"group": 3, "id": "Q-learning", "label": "Q-learning", "level": 3, "name": "Q-learning", "node_count": 13, "processed": 2, "reason_for_similarity": "Q-learning is a popular algorithm used in reinforcement learning to learn an optimal policy by estimating the value of state-action pairs. It is closely related to reinforcement learning as it aims to maximize rewards.", "shape": "dot", "size": 10, "title": "13. \u003ca href=\u0027https://en.wikipedia.org/wiki/Q-learning\u0027 target=\u0027_blank\u0027\u003eQ-learning\u003c/a\u003e\u003cbr /\u003eQ-learning is a model-free reinforcement learning algorithm to learn the value of an action in a particular state. It does not require a model of the environment, and it can handle problems with stochastic transitions and rewards without requiring adaptations.\u003cbr /\u003e[200, G3, L3, PR]", "wikipedia_canonical": "Q-learning", "wikipedia_content": "Q-learning is a model-free reinforcement learning algorithm to learn the value of an action in a particular state. It does not require a model of the environment, and it can handle problems with stochastic transitions and rewards without requiring adaptations.", "wikipedia_link": "https://en.wikipedia.org/wiki/Q-learning", "wikipedia_normalized": "Q-learning", "wikipedia_resp_code": 200}, {"group": 500, "id": "Temporal convolutional network", "label": "Temporal convolutional network", "level": 4, "name": "Temporal Convolutional Networks (TCN)", "node_count": 31, "processed": 2, "reason_for_similarity": "TCN is a type of neural network that can process sequential data using convolutional layers. While it differs from recurrent neural networks in terms of architecture, TCN can also model temporal dependencies and handle sequential data.", "shape": "dot", "size": 10, "title": "31. \u003ca href=\u0027https://en.wikipedia.org/wiki/Temporal_convolutional_network\u0027 target=\u0027_blank\u0027\u003eTemporal convolutional network\u003c/a\u003e\u003cbr /\u003e\u003cbr /\u003e[404, G500, L4, PR]", "wikipedia_canonical": "", "wikipedia_content": "", "wikipedia_link": "https://en.wikipedia.org/wiki/Temporal_convolutional_network", "wikipedia_normalized": "", "wikipedia_resp_code": 404}, {"group": 4, "id": "SARSA", "label": "SARSA", "level": 4, "name": "SARSA", "node_count": 49, "processed": 2, "reason_for_similarity": "Both SARSA and Q-learning are reinforcement learning algorithms that use the same basic idea of updating action-value estimates based on the observed rewards and next states.", "shape": "dot", "size": 10, "title": "49. \u003ca href=\u0027https://en.wikipedia.org/wiki/SARSA\u0027 target=\u0027_blank\u0027\u003eSARSA\u003c/a\u003e \u2192 \u003ca href=\u0027https://en.wikipedia.org/wiki/Sarsa\u0027 target=\u0027_blank\u0027\u003eSarsa\u003c/a\u003e\u003cbr /\u003eSarsa may refer to:PlacesSarsa, Anand, a village in the Anand District of the Indian state of Gujarat\nSarsa, Bhiwani, a village in the Bhiwani district of the Indian state of Haryana\nSarsa, Kheda, a village in the Kheda district of the Indian state of Gujarat\nSarsa, Bharuch, a village in the Bharuch district of the Indian state of Gujarat\nSarsa, Kurukshetra, a village in the kurukshetra district of the Indian state of haryanaFoodSarsa, the Philippine Spanish term for sawsawan dipping sauces in F\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Sarsa", "wikipedia_content": "Sarsa may refer to:PlacesSarsa, Anand, a village in the Anand District of the Indian state of Gujarat\nSarsa, Bhiwani, a village in the Bhiwani district of the Indian state of Haryana\nSarsa, Kheda, a village in the Kheda district of the Indian state of Gujarat\nSarsa, Bharuch, a village in the Bharuch district of the Indian state of Gujarat\nSarsa, Kurukshetra, a village in the kurukshetra district of the Indian state of haryanaFoodSarsa, the Philippine Spanish term for sawsawan dipping sauces in F", "wikipedia_link": "https://en.wikipedia.org/wiki/SARSA", "wikipedia_normalized": "Sarsa", "wikipedia_resp_code": 200}, {"group": 4, "id": "Temporal difference learning", "label": "Temporal difference learning", "level": 4, "name": "Temporal Difference Learning", "node_count": 51, "processed": 2, "reason_for_similarity": "Temporal Difference (TD) learning is a general framework that includes both Q-learning and SARSA. Q-learning and SARSA are specific instances of TD learning with different update rules.", "shape": "dot", "size": 10, "title": "51. \u003ca href=\u0027https://en.wikipedia.org/wiki/Temporal_difference_learning\u0027 target=\u0027_blank\u0027\u003eTemporal difference learning\u003c/a\u003e\u003cbr /\u003eTemporal difference (TD) learning refers to a class of model-free reinforcement learning methods which learn by bootstrapping from the current estimate of the value function. These methods sample from the environment, like Monte Carlo methods, and perform updates based on current estimates, like dynamic programming methods.\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Temporal_difference_learning", "wikipedia_content": "Temporal difference (TD) learning refers to a class of model-free reinforcement learning methods which learn by bootstrapping from the current estimate of the value function. These methods sample from the environment, like Monte Carlo methods, and perform updates based on current estimates, like dynamic programming methods.", "wikipedia_link": "https://en.wikipedia.org/wiki/Temporal_difference_learning", "wikipedia_normalized": "Temporal difference learning", "wikipedia_resp_code": 200}, {"group": 4, "id": "Information extraction", "label": "Information extraction", "level": 4, "name": "Information Extraction", "node_count": 58, "processed": 2, "reason_for_similarity": "Both information retrieval and information extraction focus on extracting relevant information from unstructured data sources.", "shape": "dot", "size": 10, "title": "58. \u003ca href=\u0027https://en.wikipedia.org/wiki/Information_extraction\u0027 target=\u0027_blank\u0027\u003eInformation extraction\u003c/a\u003e\u003cbr /\u003eInformation extraction (IE) is the task of automatically extracting structured information from unstructured and/or semi-structured machine-readable documents and other electronically represented sources. In most of the cases this activity concerns processing human language texts by means of natural language processing (NLP). Recent activities in multimedia document processing like automatic annotation and content extraction out of images/audio/video/documents could be seen as information extrac\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Information_extraction", "wikipedia_content": "Information extraction (IE) is the task of automatically extracting structured information from unstructured and/or semi-structured machine-readable documents and other electronically represented sources. In most of the cases this activity concerns processing human language texts by means of natural language processing (NLP). Recent activities in multimedia document processing like automatic annotation and content extraction out of images/audio/video/documents could be seen as information extrac", "wikipedia_link": "https://en.wikipedia.org/wiki/Information_extraction", "wikipedia_normalized": "Information extraction", "wikipedia_resp_code": 200}, {"group": 4, "id": "Document classification", "label": "Document classification", "level": 4, "name": "Document classification", "node_count": 55, "processed": 2, "reason_for_similarity": "Both involve categorizing text documents into predefined classes", "shape": "dot", "size": 10, "title": "55. \u003ca href=\u0027https://en.wikipedia.org/wiki/Document_classification\u0027 target=\u0027_blank\u0027\u003eDocument classification\u003c/a\u003e\u003cbr /\u003eDocument classification or document categorization is a problem in library science, information science and computer science. The task is to assign a document to one or more classes or categories. This may be done \"manually\" or algorithmically. The intellectual classification of documents has mostly been the province of library science, while the algorithmic classification of documents is mainly in information science and computer science. The problems are overlapping, however, and there is ther\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Document_classification", "wikipedia_content": "Document classification or document categorization is a problem in library science, information science and computer science. The task is to assign a document to one or more classes or categories. This may be done \"manually\" or algorithmically. The intellectual classification of documents has mostly been the province of library science, while the algorithmic classification of documents is mainly in information science and computer science. The problems are overlapping, however, and there is ther", "wikipedia_link": "https://en.wikipedia.org/wiki/Document_classification", "wikipedia_normalized": "Document classification", "wikipedia_resp_code": 200}, {"group": 4, "id": "Automatic summarization", "label": "Automatic summarization", "level": 4, "name": "Text summarization", "node_count": 56, "processed": 2, "reason_for_similarity": "Both involve condensing and extracting key information from text", "shape": "dot", "size": 10, "title": "56. \u003ca href=\u0027https://en.wikipedia.org/wiki/Automatic_summarization\u0027 target=\u0027_blank\u0027\u003eAutomatic summarization\u003c/a\u003e\u003cbr /\u003eAutomatic summarization is the process of shortening a set of data computationally, to create a subset that represents the most important or relevant information within the original content. Artificial intelligence algorithms are commonly developed and employed to achieve this, specialized for different types of data.\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Automatic_summarization", "wikipedia_content": "Automatic summarization is the process of shortening a set of data computationally, to create a subset that represents the most important or relevant information within the original content. Artificial intelligence algorithms are commonly developed and employed to achieve this, specialized for different types of data.", "wikipedia_link": "https://en.wikipedia.org/wiki/Automatic_summarization", "wikipedia_normalized": "Automatic summarization", "wikipedia_resp_code": 200}, {"group": 3, "id": "Information retrieval", "label": "Information retrieval", "level": 3, "name": "Information retrieval", "node_count": 16, "processed": 2, "reason_for_similarity": "Both deal with extracting relevant information from unstructured data.", "shape": "dot", "size": 10, "title": "16. \u003ca href=\u0027https://en.wikipedia.org/wiki/Information_retrieval\u0027 target=\u0027_blank\u0027\u003eInformation retrieval\u003c/a\u003e\u003cbr /\u003eInformation retrieval (IR) in computing and information science is the process of obtaining information system resources that are relevant to an information need from a collection of those resources. Searches can be based on full-text or other content-based indexing. Information retrieval is the science of searching for information in a document, searching for documents themselves, and also searching for the metadata that describes data, and for databases of texts, images or sounds.\u003cbr /\u003e[200, G3, L3, PR]", "wikipedia_canonical": "Information_retrieval", "wikipedia_content": "Information retrieval (IR) in computing and information science is the process of obtaining information system resources that are relevant to an information need from a collection of those resources. Searches can be based on full-text or other content-based indexing. Information retrieval is the science of searching for information in a document, searching for documents themselves, and also searching for the metadata that describes data, and for databases of texts, images or sounds.", "wikipedia_link": "https://en.wikipedia.org/wiki/Information_retrieval", "wikipedia_normalized": "Information retrieval", "wikipedia_resp_code": 200}, {"group": 4, "id": "Knowledge graph", "label": "Knowledge graph", "level": 4, "name": "Knowledge Graphs", "node_count": 59, "processed": 2, "reason_for_similarity": "Both information retrieval and knowledge graphs aim to organize and represent structured information for efficient retrieval and analysis.", "shape": "dot", "size": 10, "title": "59. \u003ca href=\u0027https://en.wikipedia.org/wiki/Knowledge_graph\u0027 target=\u0027_blank\u0027\u003eKnowledge graph\u003c/a\u003e\u003cbr /\u003eIn knowledge representation and reasoning, a knowledge graph is a knowledge base that uses a graph-structured data model or topology to integrate data. Knowledge graphs are often used to store interlinked descriptions of entities\u00a0\u2013 objects, events, situations or abstract concepts\u00a0\u2013 while also encoding the semantics underlying the used terminology.\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Knowledge_graph", "wikipedia_content": "In knowledge representation and reasoning, a knowledge graph is a knowledge base that uses a graph-structured data model or topology to integrate data. Knowledge graphs are often used to store interlinked descriptions of entities\u00a0\u2013 objects, events, situations or abstract concepts\u00a0\u2013 while also encoding the semantics underlying the used terminology.", "wikipedia_link": "https://en.wikipedia.org/wiki/Knowledge_graph", "wikipedia_normalized": "Knowledge graph", "wikipedia_resp_code": 200}, {"group": 4, "id": "Sparse coding", "label": "Sparse coding", "level": 4, "name": "Sparse Coding", "node_count": 37, "processed": 2, "reason_for_similarity": "Sparse Coding and Autoencoders both aim to learn a compact representation of the input data. They both use an encoder-decoder architecture to reconstruct the input while enforcing sparsity in the learned representation.", "shape": "dot", "size": 10, "title": "37. \u003ca href=\u0027https://en.wikipedia.org/wiki/Sparse_coding\u0027 target=\u0027_blank\u0027\u003eSparse coding\u003c/a\u003e \u2192 \u003ca href=\u0027https://en.wikipedia.org/wiki/Neural_coding\u0027 target=\u0027_blank\u0027\u003eNeural coding\u003c/a\u003e\u003cbr /\u003eNeural coding is a neuroscience field concerned with characterising the hypothetical relationship between the stimulus and the individual or ensemble neuronal responses and the relationship among the electrical activity of the neurons in the ensemble. Based on the theory that\nsensory and other information is represented in the brain by networks of neurons, it is thought that neurons can encode both digital and analog information.\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Neural_coding", "wikipedia_content": "Neural coding is a neuroscience field concerned with characterising the hypothetical relationship between the stimulus and the individual or ensemble neuronal responses and the relationship among the electrical activity of the neurons in the ensemble. Based on the theory that\nsensory and other information is represented in the brain by networks of neurons, it is thought that neurons can encode both digital and analog information.", "wikipedia_link": "https://en.wikipedia.org/wiki/Sparse_coding", "wikipedia_normalized": "Neural coding", "wikipedia_resp_code": 200}, {"group": 4, "id": "Recommender system", "label": "Recommender system", "level": 4, "name": "Recommender Systems", "node_count": 57, "processed": 2, "reason_for_similarity": "Both information retrieval and recommender systems aim to provide relevant and personalized recommendations based on user preferences.", "shape": "dot", "size": 10, "title": "57. \u003ca href=\u0027https://en.wikipedia.org/wiki/Recommender_system\u0027 target=\u0027_blank\u0027\u003eRecommender system\u003c/a\u003e\u003cbr /\u003eA recommender system, or a recommendation system, is a subclass of information filtering system that provide suggestions for items that are most pertinent to a particular user. Typically, the suggestions refer to various decision-making processes, such as what product to purchase, what music to listen to, or what online news to read. Recommender systems are particularly useful when an individual needs to choose an item from a potentially overwhelming number of items that a service may offer.\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Recommender_system", "wikipedia_content": "A recommender system, or a recommendation system, is a subclass of information filtering system that provide suggestions for items that are most pertinent to a particular user. Typically, the suggestions refer to various decision-making processes, such as what product to purchase, what music to listen to, or what online news to read. Recommender systems are particularly useful when an individual needs to choose an item from a potentially overwhelming number of items that a service may offer.", "wikipedia_link": "https://en.wikipedia.org/wiki/Recommender_system", "wikipedia_normalized": "Recommender system", "wikipedia_resp_code": 200}, {"group": 500, "id": "Temporal modeling", "label": "Temporal modeling", "level": 4, "name": "Temporal modeling", "node_count": 77, "processed": 2, "reason_for_similarity": "Video analysis often requires modeling the temporal dependencies and patterns in videos, which is the focus of temporal modeling.", "shape": "dot", "size": 10, "title": "77. \u003ca href=\u0027https://en.wikipedia.org/wiki/Temporal_modeling\u0027 target=\u0027_blank\u0027\u003eTemporal modeling\u003c/a\u003e\u003cbr /\u003e\u003cbr /\u003e[404, G500, L4, PR]", "wikipedia_canonical": "", "wikipedia_content": "", "wikipedia_link": "https://en.wikipedia.org/wiki/Temporal_modeling", "wikipedia_normalized": "", "wikipedia_resp_code": 404}, {"group": 4, "id": "Video segmentation", "label": "Video segmentation", "level": 4, "name": "Video segmentation", "node_count": 76, "processed": 2, "reason_for_similarity": "Video analysis often involves segmenting videos into meaningful regions or objects, which is the primary goal of video segmentation.", "shape": "dot", "size": 10, "title": "76. \u003ca href=\u0027https://en.wikipedia.org/wiki/Video_segmentation\u0027 target=\u0027_blank\u0027\u003eVideo segmentation\u003c/a\u003e \u2192 \u003ca href=\u0027https://en.wikipedia.org/wiki/Image_segmentation\u0027 target=\u0027_blank\u0027\u003eImage segmentation\u003c/a\u003e\u003cbr /\u003eIn digital image processing and computer vision, image segmentation is the process of partitioning a digital image into multiple image segments, also known as image regions or image objects. The goal of segmentation is to simplify and/or change the representation of an image into something that is more meaningful and easier to analyze. Image segmentation is typically used to locate objects and boundaries in images. More precisely, image segmentation is the process of assigning a label to every p\u003cbr /\u003e[200, G4, L4, PR]", "wikipedia_canonical": "Image_segmentation", "wikipedia_content": "In digital image processing and computer vision, image segmentation is the process of partitioning a digital image into multiple image segments, also known as image regions or image objects. The goal of segmentation is to simplify and/or change the representation of an image into something that is more meaningful and easier to analyze. Image segmentation is typically used to locate objects and boundaries in images. More precisely, image segmentation is the process of assigning a label to every p", "wikipedia_link": "https://en.wikipedia.org/wiki/Video_segmentation", "wikipedia_normalized": "Image segmentation", "wikipedia_resp_code": 200}]);
                  edges = new vis.DataSet([{"arrows": "to", "from": "Image segmentation", "to": "Object detection", "width": 1}, {"arrows": "to", "from": "Image segmentation", "to": "Instance segmentation", "width": 1}, {"arrows": "to", "from": "Image segmentation", "to": "Semantic segmentation", "width": 1}, {"arrows": "to", "from": "Convolutional neural network", "to": "Recurrent neural network", "width": 1}, {"arrows": "to", "from": "Convolutional neural network", "to": "Generative adversarial network", "width": 1}, {"arrows": "to", "from": "Convolutional neural network", "to": "Deep belief network", "width": 1}, {"arrows": "to", "from": "Convolutional neural network", "to": "Long short-term memory", "width": 1}, {"arrows": "to", "from": "Convolutional neural network", "to": "Autoencoder", "width": 1}, {"arrows": "to", "from": "Sequence-to-sequence model", "to": "Recurrent neural network", "width": 1}, {"arrows": "to", "from": "Sequence-to-sequence model", "to": "Transformer (machine learning model)", "width": 1}, {"arrows": "to", "from": "Transformer (machine learning model)", "to": "Recurrent neural network", "width": 1}, {"arrows": "to", "from": "Transformer (machine learning model)", "to": "Sequence-to-sequence model", "width": 1}, {"arrows": "to", "from": "Gating mechanism", "to": "Long short-term memory", "width": 1}, {"arrows": "to", "from": "Gating mechanism", "to": "Gated recurrent unit", "width": 1}, {"arrows": "to", "from": "Gating mechanism", "to": "Transformer (machine learning model)", "width": 1}, {"arrows": "to", "from": "Part-of-speech tagging", "to": "Text classification", "width": 1}, {"arrows": "to", "from": "Part-of-speech tagging", "to": "Sentiment analysis", "width": 1}, {"arrows": "to", "from": "Part-of-speech tagging", "to": "Dependency parsing", "width": 1}, {"arrows": "to", "from": "Partially observable Markov decision process", "to": "Reinforcement learning", "width": 1}, {"arrows": "to", "from": "Partially observable Markov decision process", "to": "Hidden Markov model", "width": 1}, {"arrows": "to", "from": "Variational autoencoder", "to": "Generative adversarial network", "width": 1}, {"arrows": "to", "from": "Variational autoencoder", "to": "Restricted Boltzmann machine", "width": 1}, {"arrows": "to", "from": "Variational autoencoder", "to": "Autoencoder", "width": 1}, {"arrows": "to", "from": "Variational autoencoder", "to": "Deep belief network", "width": 1}, {"arrows": "to", "from": "Variational autoencoder", "to": "Latent Dirichlet allocation", "width": 1}, {"arrows": "to", "from": "Boltzmann machine", "to": "Restricted Boltzmann machine", "width": 1}, {"arrows": "to", "from": "Boltzmann machine", "to": "Hopfield network", "width": 0.8}, {"arrows": "to", "from": "Boltzmann machine", "to": "Deep belief network", "width": 0.9}, {"arrows": "to", "from": "Boltzmann machine", "to": "Deep Boltzmann machine", "width": 0.9}, {"arrows": "to", "from": "Object recognition", "to": "Object detection", "width": 1}, {"arrows": "to", "from": "Object recognition", "to": "Semantic segmentation", "width": 1}, {"arrows": "to", "from": "Object recognition", "to": "Instance segmentation", "width": 1}, {"arrows": "to", "from": "Object recognition", "to": "Object tracking", "width": 1}, {"arrows": "to", "from": "Artificial intelligence", "to": "Deep learning", "width": 1}, {"arrows": "to", "from": "Artificial intelligence", "to": "Reinforcement learning", "width": 1}, {"arrows": "to", "from": "Artificial intelligence", "to": "Natural language processing", "width": 1}, {"arrows": "to", "from": "Artificial intelligence", "to": "Computer vision", "width": 1}, {"arrows": "to", "from": "Artificial intelligence", "to": "Generative adversarial network", "width": 1}, {"arrows": "to", "from": "Topic model", "to": "Latent Dirichlet allocation", "width": 1}, {"arrows": "to", "from": "Semantic segmentation", "to": "Instance segmentation", "width": 1}, {"arrows": "to", "from": "Semantic segmentation", "to": "Object detection", "width": 1}, {"arrows": "to", "from": "Semantic segmentation", "to": "Pattern recognition", "width": 1}, {"arrows": "to", "from": "Semantic segmentation", "to": "Object tracking", "width": 1}, {"arrows": "to", "from": "Semantic segmentation", "to": "Scene understanding", "width": 1}, {"arrows": "to", "from": "Restricted Boltzmann machine", "to": "Deep belief network", "width": 1}, {"arrows": "to", "from": "Restricted Boltzmann machine", "to": "Hopfield network", "width": 1}, {"arrows": "to", "from": "Restricted Boltzmann machine", "to": "Boltzmann machine", "width": 1}, {"arrows": "to", "from": "Restricted Boltzmann machine", "to": "Deep Boltzmann machine", "width": 1}, {"arrows": "to", "from": "Restricted Boltzmann machine", "to": "Autoencoder", "width": 1}, {"arrows": "to", "from": "Sequence model", "to": "Recurrent neural network", "width": 1}, {"arrows": "to", "from": "Sequence model", "to": "Hidden Markov model", "width": 1}, {"arrows": "to", "from": "Sequence model", "to": "Long short-term memory", "width": 1}, {"arrows": "to", "from": "Sequence model", "to": "Transformer (machine learning model)", "width": 1}, {"arrows": "to", "from": "Cluster analysis", "to": "Self-organizing map", "width": 1}, {"arrows": "to", "from": "Image recognition", "to": "Object detection", "width": 1}, {"arrows": "to", "from": "Image recognition", "to": "Image segmentation", "width": 1}, {"arrows": "to", "from": "Image recognition", "to": "Pattern recognition", "width": 1}, {"arrows": "to", "from": "Image recognition", "to": "Convolutional neural network", "width": 1}, {"arrows": "to", "from": "Image recognition", "to": "Deep learning", "width": 1}, {"arrows": "to", "from": "Deep generative model", "to": "Autoencoder#Variational autoencoder (VAE)", "width": 1}, {"arrows": "to", "from": "Deep generative model", "to": "Generative adversarial network", "width": 1}, {"arrows": "to", "from": "Deep generative model", "to": "Boltzmann machine", "width": 1}, {"arrows": "to", "from": "Deep generative model", "to": "Restricted Boltzmann machine", "width": 1}, {"arrows": "to", "from": "Deep generative model", "to": "Deep belief network", "width": 1}, {"arrows": "to", "from": "Computer vision", "to": "Image recognition", "width": 1}, {"arrows": "to", "from": "Computer vision", "to": "Object detection", "width": 1}, {"arrows": "to", "from": "Computer vision", "to": "Semantic segmentation", "width": 1}, {"arrows": "to", "from": "Computer vision", "to": "Instance segmentation", "width": 1}, {"arrows": "to", "from": "Computer vision", "to": "Video analysis", "width": 1}, {"arrows": "to", "from": "Dimensionality reduction", "to": "Autoencoder", "width": 1}, {"arrows": "to", "from": "Unsupervised learning", "to": "Cluster analysis", "width": 1}, {"arrows": "to", "from": "Unsupervised learning", "to": "Dimensionality reduction", "width": 1}, {"arrows": "to", "from": "Unsupervised learning", "to": "Anomaly detection", "width": 1}, {"arrows": "to", "from": "Unsupervised learning", "to": "Generative model", "width": 1}, {"arrows": "to", "from": "Unsupervised learning", "to": "Self-organizing map", "width": 1}, {"arrows": "to", "from": "Instance recognition", "to": "Object recognition", "width": 1}, {"arrows": "to", "from": "Instance recognition", "to": "Object detection", "width": 1}, {"arrows": "to", "from": "Instance recognition", "to": "Semantic segmentation", "width": 1}, {"arrows": "to", "from": "Instance recognition", "to": "Instance segmentation", "width": 1}, {"arrows": "to", "from": "Deep Boltzmann machine", "to": "Restricted Boltzmann machine", "width": 1}, {"arrows": "to", "from": "Deep Boltzmann machine", "to": "Deep belief network", "width": 1}, {"arrows": "to", "from": "Deep Boltzmann machine", "to": "Generative adversarial network", "width": 1}, {"arrows": "to", "from": "Deep Boltzmann machine", "to": "Autoencoder#Variational autoencoder (VAE)", "width": 1}, {"arrows": "to", "from": "Deep Boltzmann machine", "to": "Belief propagation#Deep belief propagation", "width": 1}, {"arrows": "to", "from": "Dynamic programming", "to": "Reinforcement learning", "width": 1}, {"arrows": "to", "from": "Dynamic programming", "to": "Markov decision process", "width": 1}, {"arrows": "to", "from": "Generative model", "to": "Hidden Markov model", "width": 1}, {"arrows": "to", "from": "Temporal dependency", "to": "Recurrent neural network", "width": 1}, {"arrows": "to", "from": "Temporal dependency", "to": "Hidden Markov model", "width": 1}, {"arrows": "to", "from": "Temporal dependency", "to": "Long short-term memory", "width": 1}, {"arrows": "to", "from": "Action recognition", "to": "Object recognition", "width": 1}, {"arrows": "to", "from": "Scene understanding", "to": "Object recognition", "width": 1}, {"arrows": "to", "from": "Scene understanding", "to": "Semantic segmentation", "width": 1}, {"arrows": "to", "from": "Speech recognition", "to": "Natural language processing", "width": 1}, {"arrows": "to", "from": "Speech recognition", "to": "Audio signal processing", "width": 1}, {"arrows": "to", "from": "Speech recognition", "to": "Hidden Markov model", "width": 1}, {"arrows": "to", "from": "Speech recognition", "to": "Recurrent neural network", "width": 1}, {"arrows": "to", "from": "Speech recognition", "to": "Automatic speech recognition", "width": 1}, {"arrows": "to", "from": "Policy gradient methods", "to": "Reinforcement learning", "width": 1}, {"arrows": "to", "from": "Policy gradient methods", "to": "Gradient descent", "width": 1}, {"arrows": "to", "from": "Policy gradient methods", "to": "Markov decision process", "width": 1}, {"arrows": "to", "from": "Policy gradient methods", "to": "Monte Carlo method", "width": 1}, {"arrows": "to", "from": "Policy gradient methods", "to": "Actor\u2013critic method", "width": 1}, {"arrows": "to", "from": "Object tracking", "to": "Object detection", "width": 1}, {"arrows": "to", "from": "Object tracking", "to": "Image segmentation", "width": 1}, {"arrows": "to", "from": "Dependency parsing", "to": "Named-entity recognition", "width": 1}, {"arrows": "to", "from": "Dependency parsing", "to": "Part-of-speech tagging", "width": 1}, {"arrows": "to", "from": "Dependency parsing", "to": "Coreference resolution", "width": 1}, {"arrows": "to", "from": "Object detection", "to": "Image segmentation", "width": 1}, {"arrows": "to", "from": "Object detection", "to": "Instance segmentation", "width": 1}, {"arrows": "to", "from": "Object detection", "to": "Semantic segmentation", "width": 1}, {"arrows": "to", "from": "Object detection", "to": "Object recognition", "width": 1}, {"arrows": "to", "from": "Object detection", "to": "Object tracking", "width": 1}, {"arrows": "to", "from": "Pattern recognition", "to": "Supervised learning", "width": 1}, {"arrows": "to", "from": "Pattern recognition", "to": "Unsupervised learning", "width": 1}, {"arrows": "to", "from": "Pattern recognition", "to": "Natural language processing", "width": 1}, {"arrows": "to", "from": "Active learning (machine learning)", "to": "Semi-supervised learning", "width": 1}, {"arrows": "to", "from": "Active learning (machine learning)", "to": "Reinforcement learning", "width": 1}, {"arrows": "to", "from": "Active learning (machine learning)", "to": "Transfer learning", "width": 1}, {"arrows": "to", "from": "Semi-supervised learning", "to": "Transfer learning", "width": 1}, {"arrows": "to", "from": "Belief propagation#Deep belief propagation", "to": "Restricted Boltzmann machine", "width": 1}, {"arrows": "to", "from": "Belief propagation#Deep belief propagation", "to": "Variational autoencoder", "width": 1}, {"arrows": "to", "from": "Sentiment analysis", "to": "Text classification", "width": 1}, {"arrows": "to", "from": "Sentiment analysis", "to": "Natural language processing", "width": 1}, {"arrows": "to", "from": "Sentiment analysis", "to": "Opinion mining", "width": 1}, {"arrows": "to", "from": "Sentiment analysis", "to": "Emotion recognition", "width": 1}, {"arrows": "to", "from": "Sentiment analysis", "to": "Social media analysis", "width": 1}, {"arrows": "to", "from": "Deep Q-Networks", "to": "Reinforcement learning", "width": 1}, {"arrows": "to", "from": "Deep Q-Networks", "to": "Q-learning", "width": 1}, {"arrows": "to", "from": "Temporal convolutional network", "to": "Recurrent neural network", "width": 1}, {"arrows": "to", "from": "Temporal convolutional network", "to": "Long short-term memory", "width": 1}, {"arrows": "to", "from": "Temporal convolutional network", "to": "Convolutional neural network", "width": 1}, {"arrows": "to", "from": "Temporal convolutional network", "to": "Transformer (machine learning model)", "width": 1}, {"arrows": "to", "from": "Temporal convolutional network", "to": "Gated recurrent unit", "width": 1}, {"arrows": "to", "from": "Long short-term memory", "to": "Gated recurrent unit", "width": 1}, {"arrows": "to", "from": "Long short-term memory", "to": "Recurrent neural network", "width": 1}, {"arrows": "to", "from": "Long short-term memory", "to": "Gating mechanism", "width": 1}, {"arrows": "to", "from": "Long short-term memory", "to": "Sequence model", "width": 1}, {"arrows": "to", "from": "Long short-term memory", "to": "Temporal dependency", "width": 1}, {"arrows": "to", "from": "Gated recurrent unit", "to": "Long short-term memory", "width": 1}, {"arrows": "to", "from": "Gated recurrent unit", "to": "Recurrent neural network", "width": 1}, {"arrows": "to", "from": "Gated recurrent unit", "to": "Transformer (machine learning model)", "width": 1}, {"arrows": "to", "from": "Gated recurrent unit", "to": "Sequence-to-sequence model", "width": 1}, {"arrows": "to", "from": "Q-learning", "to": "SARSA", "width": 1}, {"arrows": "to", "from": "Q-learning", "to": "Deep Q-Networks", "width": 1}, {"arrows": "to", "from": "Q-learning", "to": "Temporal difference learning", "width": 1}, {"arrows": "to", "from": "Q-learning", "to": "Monte Carlo method", "width": 1}, {"arrows": "to", "from": "Q-learning", "to": "Policy gradient methods", "width": 1}, {"arrows": "to", "from": "Named-entity recognition", "to": "Part-of-speech tagging", "width": 1}, {"arrows": "to", "from": "Named-entity recognition", "to": "Text classification", "width": 1}, {"arrows": "to", "from": "Named-entity recognition", "to": "Information extraction", "width": 1}, {"arrows": "to", "from": "Named-entity recognition", "to": "Dependency parsing", "width": 1}, {"arrows": "to", "from": "Named-entity recognition", "to": "Coreference resolution", "width": 1}, {"arrows": "to", "from": "Instance segmentation", "to": "Semantic segmentation", "width": 1}, {"arrows": "to", "from": "Instance segmentation", "to": "Object detection", "width": 1}, {"arrows": "to", "from": "Instance segmentation", "to": "Image segmentation", "width": 1}, {"arrows": "to", "from": "Instance segmentation", "to": "Instance recognition", "width": 1}, {"arrows": "to", "from": "Instance segmentation", "to": "Object tracking", "width": 1}, {"arrows": "to", "from": "Hopfield network", "to": "Boltzmann machine", "width": 1}, {"arrows": "to", "from": "Hopfield network", "to": "Restricted Boltzmann machine", "width": 1}, {"arrows": "to", "from": "Hopfield network", "to": "Recurrent neural network", "width": 1}, {"arrows": "to", "from": "Text classification", "to": "Sentiment analysis", "width": 1}, {"arrows": "to", "from": "Text classification", "to": "Named-entity recognition", "width": 1}, {"arrows": "to", "from": "Text classification", "to": "Topic model", "width": 1}, {"arrows": "to", "from": "Text classification", "to": "Document classification", "width": 1}, {"arrows": "to", "from": "Text classification", "to": "Automatic summarization", "width": 1}, {"arrows": "to", "from": "Information extraction", "to": "Natural language processing", "width": 1}, {"arrows": "to", "from": "Information extraction", "to": "Named-entity recognition", "width": 1}, {"arrows": "to", "from": "Information extraction", "to": "Information retrieval", "width": 1}, {"arrows": "to", "from": "Information extraction", "to": "Knowledge graph", "width": 1}, {"arrows": "to", "from": "Opinion mining", "to": "Sentiment analysis", "width": 1}, {"arrows": "to", "from": "Opinion mining", "to": "Text classification", "width": 1}, {"arrows": "to", "from": "Opinion mining", "to": "Natural language processing", "width": 1}, {"arrows": "to", "from": "Hidden Markov model", "to": "Recurrent neural network", "width": 1}, {"arrows": "to", "from": "Autoencoder#Variational autoencoder (VAE)", "to": "Generative adversarial network", "width": 1}, {"arrows": "to", "from": "Autoencoder#Variational autoencoder (VAE)", "to": "Restricted Boltzmann machine", "width": 1}, {"arrows": "to", "from": "Autoencoder#Variational autoencoder (VAE)", "to": "Deep belief network", "width": 1}, {"arrows": "to", "from": "Autoencoder#Variational autoencoder (VAE)", "to": "Deep generative model", "width": 1}, {"arrows": "to", "from": "Audio signal processing", "to": "Speech recognition", "width": 1}, {"arrows": "to", "from": "Recurrent neural network", "to": "Long short-term memory", "width": 1}, {"arrows": "to", "from": "Recurrent neural network", "to": "Gated recurrent unit", "width": 1}, {"arrows": "to", "from": "Recurrent neural network", "to": "Sequence-to-sequence model", "width": 1}, {"arrows": "to", "from": "Recurrent neural network", "to": "Temporal convolutional network", "width": 1}, {"arrows": "to", "from": "Recurrent neural network", "to": "Transformer (machine learning model)", "width": 1}, {"arrows": "to", "from": "Transfer learning", "to": "Semi-supervised learning", "width": 1}, {"arrows": "to", "from": "Deep learning", "to": "Recurrent neural network", "width": 1}, {"arrows": "to", "from": "Deep learning", "to": "Convolutional neural network", "width": 1}, {"arrows": "to", "from": "Deep learning", "to": "Generative adversarial network", "width": 1}, {"arrows": "to", "from": "Deep learning", "to": "Long short-term memory", "width": 1}, {"arrows": "to", "from": "Deep learning", "to": "Autoencoder", "width": 1}, {"arrows": "to", "from": "Automatic summarization", "to": "Natural language processing", "width": 1}, {"arrows": "to", "from": "Automatic summarization", "to": "Information retrieval", "width": 1}, {"arrows": "to", "from": "Actor\u2013critic method", "to": "Q-learning", "width": 1}, {"arrows": "to", "from": "Actor\u2013critic method", "to": "Policy gradient methods", "width": 1}, {"arrows": "to", "from": "Actor\u2013critic method", "to": "Temporal difference learning", "width": 1}, {"arrows": "to", "from": "Actor\u2013critic method", "to": "Monte Carlo method", "width": 1}, {"arrows": "to", "from": "Automatic speech recognition", "to": "Speech recognition", "width": 1}, {"arrows": "to", "from": "Automatic speech recognition", "to": "Natural language processing", "width": 1}, {"arrows": "to", "from": "Automatic speech recognition", "to": "Audio signal processing", "width": 1}, {"arrows": "to", "from": "Automatic speech recognition", "to": "Hidden Markov model", "width": 1}, {"arrows": "to", "from": "Automatic speech recognition", "to": "Recurrent neural network", "width": 1}, {"arrows": "to", "from": "Coreference resolution", "to": "Named-entity recognition", "width": 1}, {"arrows": "to", "from": "Coreference resolution", "to": "Text classification", "width": 1}, {"arrows": "to", "from": "Coreference resolution", "to": "Information extraction", "width": 1}, {"arrows": "to", "from": "SARSA", "to": "Q-learning", "width": 1}, {"arrows": "to", "from": "SARSA", "to": "Temporal difference learning", "width": 1}, {"arrows": "to", "from": "SARSA", "to": "Monte Carlo method", "width": 1}, {"arrows": "to", "from": "SARSA", "to": "Policy gradient methods", "width": 1}, {"arrows": "to", "from": "Generative adversarial network", "to": "Variational autoencoder", "width": 1}, {"arrows": "to", "from": "Generative adversarial network", "to": "Deep Boltzmann machine", "width": 1}, {"arrows": "to", "from": "Generative adversarial network", "to": "Autoencoder", "width": 1}, {"arrows": "to", "from": "Generative adversarial network", "to": "Restricted Boltzmann machine", "width": 1}, {"arrows": "to", "from": "Generative adversarial network", "to": "Deep generative model", "width": 1}, {"arrows": "to", "from": "Temporal difference learning", "to": "Q-learning", "width": 1}, {"arrows": "to", "from": "Temporal difference learning", "to": "Monte Carlo method", "width": 1}, {"arrows": "to", "from": "Autoencoder", "to": "Restricted Boltzmann machine", "width": 1}, {"arrows": "to", "from": "Autoencoder", "to": "Variational autoencoder", "width": 1}, {"arrows": "to", "from": "Autoencoder", "to": "Sparse coding", "width": 1}, {"arrows": "to", "from": "Autoencoder", "to": "Deep belief network", "width": 1}, {"arrows": "to", "from": "Autoencoder", "to": "Generative adversarial network", "width": 1}, {"arrows": "to", "from": "Markov decision process", "to": "Reinforcement learning", "width": 1}, {"arrows": "to", "from": "Markov decision process", "to": "Partially observable Markov decision process", "width": 1}, {"arrows": "to", "from": "Markov decision process", "to": "Dynamic programming", "width": 1}, {"arrows": "to", "from": "Markov decision process", "to": "Q-learning", "width": 1}, {"arrows": "to", "from": "Markov decision process", "to": "Monte Carlo method", "width": 1}, {"arrows": "to", "from": "Information retrieval", "to": "Natural language processing", "width": 1}, {"arrows": "to", "from": "Information retrieval", "to": "Recommender system", "width": 1}, {"arrows": "to", "from": "Information retrieval", "to": "Text classification", "width": 1}, {"arrows": "to", "from": "Information retrieval", "to": "Information extraction", "width": 1}, {"arrows": "to", "from": "Information retrieval", "to": "Knowledge graph", "width": 1}, {"arrows": "to", "from": "Supervised learning", "to": "Unsupervised learning", "width": 1}, {"arrows": "to", "from": "Supervised learning", "to": "Semi-supervised learning", "width": 1}, {"arrows": "to", "from": "Supervised learning", "to": "Reinforcement learning", "width": 1}, {"arrows": "to", "from": "Supervised learning", "to": "Transfer learning", "width": 1}, {"arrows": "to", "from": "Supervised learning", "to": "Active learning (machine learning)", "width": 1}, {"arrows": "to", "from": "Document classification", "to": "Text classification", "width": 1}, {"arrows": "to", "from": "Document classification", "to": "Sentiment analysis", "width": 1}, {"arrows": "to", "from": "Document classification", "to": "Topic model", "width": 1}, {"arrows": "to", "from": "Document classification", "to": "Named-entity recognition", "width": 1}, {"arrows": "to", "from": "Document classification", "to": "Information retrieval", "width": 1}, {"arrows": "to", "from": "Deep belief network", "to": "Restricted Boltzmann machine", "width": 1}, {"arrows": "to", "from": "Deep belief network", "to": "Deep Boltzmann machine", "width": 1}, {"arrows": "to", "from": "Deep belief network", "to": "Convolutional neural network", "width": 1}, {"arrows": "to", "from": "Deep belief network", "to": "Autoencoder", "width": 1}, {"arrows": "to", "from": "Deep belief network", "to": "Generative adversarial network", "width": 1}, {"arrows": "to", "from": "Social media analysis", "to": "Sentiment analysis", "width": 1}, {"arrows": "to", "from": "Social media analysis", "to": "Text classification", "width": 1}, {"arrows": "to", "from": "Social media analysis", "to": "Topic model", "width": 1}, {"arrows": "to", "from": "Emotion recognition", "to": "Sentiment analysis", "width": 1}, {"arrows": "to", "from": "Temporal modeling", "to": "Recurrent neural network", "width": 1}, {"arrows": "to", "from": "Temporal modeling", "to": "Hidden Markov model", "width": 1}, {"arrows": "to", "from": "Temporal modeling", "to": "Long short-term memory", "width": 1}, {"arrows": "to", "from": "Video segmentation", "to": "Image segmentation", "width": 1}, {"arrows": "to", "from": "Video segmentation", "to": "Object detection", "width": 1}, {"arrows": "to", "from": "Video segmentation", "to": "Semantic segmentation", "width": 1}, {"arrows": "to", "from": "Video segmentation", "to": "Instance segmentation", "width": 1}, {"arrows": "to", "from": "Natural language processing", "to": "Text classification", "width": 1}, {"arrows": "to", "from": "Natural language processing", "to": "Information retrieval", "width": 1}, {"arrows": "to", "from": "Natural language processing", "to": "Speech recognition", "width": 1}, {"arrows": "to", "from": "Natural language processing", "to": "Named-entity recognition", "width": 1}, {"arrows": "to", "from": "Natural language processing", "to": "Sentiment analysis", "width": 1}, {"arrows": "to", "from": "Sparse coding", "to": "Autoencoder", "width": 1}, {"arrows": "to", "from": "Reinforcement learning", "to": "Supervised learning", "width": 1}, {"arrows": "to", "from": "Reinforcement learning", "to": "Unsupervised learning", "width": 1}, {"arrows": "to", "from": "Reinforcement learning", "to": "Markov decision process", "width": 1}, {"arrows": "to", "from": "Reinforcement learning", "to": "Q-learning", "width": 1}, {"arrows": "to", "from": "Reinforcement learning", "to": "Policy gradient methods", "width": 1}, {"arrows": "to", "from": "Video analysis", "to": "Computer vision", "width": 1}, {"arrows": "to", "from": "Video analysis", "to": "Object detection", "width": 1}, {"arrows": "to", "from": "Video analysis", "to": "Action recognition", "width": 1}, {"arrows": "to", "from": "Video analysis", "to": "Video segmentation", "width": 1}, {"arrows": "to", "from": "Video analysis", "to": "Temporal modeling", "width": 1}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {
    "configure": {
        "enabled": true,
        "filter": [
            "physics"
        ]
    },
    "edges": {
        "color": {
            "inherit": true
        },
        "smooth": {
            "enabled": true,
            "type": "dynamic"
        }
    },
    "interaction": {
        "dragNodes": true,
        "hideEdgesOnDrag": false,
        "hideNodesOnDrag": false
    },
    "physics": {
        "enabled": true,
        "forceAtlas2Based": {
            "avoidOverlap": 0,
            "centralGravity": 0.01,
            "damping": 0.4,
            "gravitationalConstant": -50,
            "springConstant": 0.03,
            "springLength": 100
        },
        "solver": "forceAtlas2Based",
        "stabilization": {
            "enabled": true,
            "fit": true,
            "iterations": 1000,
            "onlyDynamicEdges": false,
            "updateInterval": 50
        }
    }
};

                  


                  
                  // if this network requires displaying the configure window,
                  // put it in its div
                  options.configure["container"] = document.getElementById("config");
                  

                  network = new vis.Network(container, data, options);

                  

                  

                  
                  // make a custom popup
                      var popup = document.createElement("div");
                      popup.className = 'popup';
                      popupTimeout = null;
                      popup.addEventListener('mouseover', function () {
                          console.log(popup)
                          if (popupTimeout !== null) {
                              clearTimeout(popupTimeout);
                              popupTimeout = null;
                          }
                      });
                      popup.addEventListener('mouseout', function () {
                          if (popupTimeout === null) {
                              hidePopup();
                          }
                      });
                      container.appendChild(popup);


                      // use the popup event to show
                      network.on("showPopup", function (params) {
                          showPopup(params);
                      });

                      // use the hide event to hide it
                      network.on("hidePopup", function (params) {
                          hidePopup();
                      });

                      // hiding the popup through css
                      function hidePopup() {
                          popupTimeout = setTimeout(function () { popup.style.display = 'none'; }, 500);
                      }

                      // showing the popup
                      function showPopup(nodeId) {
                          // get the data from the vis.DataSet
                          var nodeData = nodes.get([nodeId]);
                          popup.innerHTML = nodeData[0].title;

                          // get the position of the node
                          var posCanvas = network.getPositions([nodeId])[nodeId];

                          // get the bounding box of the node
                          var boundingBox = network.getBoundingBox(nodeId);

                          //position tooltip:
                          posCanvas.x = posCanvas.x + 0.5 * (boundingBox.right - boundingBox.left);

                          // convert coordinates to the DOM space
                          var posDOM = network.canvasToDOM(posCanvas);

                          // Give it an offset
                          posDOM.x += 10;
                          posDOM.y -= 20;

                          // show and place the tooltip.
                          popup.style.display = 'block';
                          popup.style.top = posDOM.y + 'px';
                          popup.style.left = posDOM.x + 'px';
                      }
                  


                  

                  return network;

              }
              drawGraph();
        </script>
    </body>
</html>