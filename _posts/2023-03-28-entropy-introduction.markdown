---
layout:     post
title:      "Entropy: A History and Introduction"
subtitle:   "Bringing order to the concept of Entropy"
date:       2023-03-28 09:00:00
tags:       [Entropy, Information, Data, Physics, Thermodynamics]
author:     "Dylan Hogg"
header-img: "img/post-bg-04.jpg"
published:  true
comments:   true
---

<style>
    .center {
      width: 60%;
      margin: 0 auto;
    }

    /* substack copy pasta css hacks: */
    /*  also, replace class="image-caption" with class="image-caption caption" */
    .captioned-image-container {
      width: 60%;
      margin: 0 auto;
    }
    .img-responsive {
      width: 100%;
      margin: 0 auto;
    }
    .image-caption {
      width: 80%;
      margin: 0 auto;
      font-size: smaller;
      color: #777;
    }
</style>

<h2>Overview</h2>
<p>Entropy is a notoriously tricky concept. It’s associated with many ideas: disorder, randomness, messiness, uncertainty, information, energy and the arrow of time to name a few. To complicate matters, the notion of entropy originated from different fields: thermodynamics and statistical mechanics (which are both branches of physics) and later, information theory (which is a branch of mathematics and computer science).</p>

<p>In this post we’ll explore the evolution and generalisation of the concept of entropy, see how it relates to both physics and information, discuss paradoxes, demons, black holes and the end of the universe.</p>

<p>Prior to research for this post, I understood entropy at a surface level having used it in a machine learning context and reading about it in popular science books. This is my attempt to understand entropy in its various forms at a deeper level.</p>
<div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb436bd27-14db-4406-b7e5-ac4eacea2592_1024x1024.png"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb436bd27-14db-4406-b7e5-ac4eacea2592_1024x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb436bd27-14db-4406-b7e5-ac4eacea2592_1024x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb436bd27-14db-4406-b7e5-ac4eacea2592_1024x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb436bd27-14db-4406-b7e5-ac4eacea2592_1024x1024.png 1456w" sizes="100vw"><img src="https://substack-post-media.s3.amazonaws.com/public/images/b436bd27-14db-4406-b7e5-ac4eacea2592_1024x1024.png" width="448" height="448" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b436bd27-14db-4406-b7e5-ac4eacea2592_1024x1024.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1024,&quot;width&quot;:1024,&quot;resizeWidth&quot;:448,&quot;bytes&quot;:2623819,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb436bd27-14db-4406-b7e5-ac4eacea2592_1024x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb436bd27-14db-4406-b7e5-ac4eacea2592_1024x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb436bd27-14db-4406-b7e5-ac4eacea2592_1024x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb436bd27-14db-4406-b7e5-ac4eacea2592_1024x1024.png 1456w" sizes="100vw"></picture><div class="image-link-expand"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="#FFFFFF" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" y1="3" x2="14" y2="10"></line><line x1="3" y1="21" x2="10" y2="14"></line></svg></div></div></a><figcaption class="image-caption caption">A DALL·E interpretation of entropy (<a href="https://labs.openai.com/s/OwMSk4NFIuDQQxWfowjHxZg2">source</a>)</figcaption></figure></div><h2>What is Entropy?</h2>
<p>Entropy is basically a measure of randomness. If your room is tidy and organised, you can say it has a low entropy arrangement. However, if your room is a mess with things everywhere randomly, you can say it has a high entropy arrangement. In some sense, entropy is related to the number of ways objects can be arranged: there are many more ways for a room to be messy compared to organised. This imbalance between messy vs. organised states is at the heart of entropy and leads to very interesting results for any system, including your room or even the entire universe!</p>
<p><a href="https://en.wikipedia.org/wiki/Entropy">Wikipedia</a> describes entropy as: “a measurable physical property, that is most commonly associated with a state of disorder, randomness, or uncertainty. The term and the concept are used in diverse fields, from classical thermodynamics, where it was first recognised, to the microscopic description of nature in statistical physics, and to the principles of information theory.”</p>

<p>The use of the term entropy in multiple fields is one reason it can be a confusing concept as it is defined and interpreted somewhat different is each. Let’s review the three main fields it’s used:</p>
<ol><li>
<p><a href="https://en.wikipedia.org/wiki/Thermodynamics">Thermodynamics</a> is a branch of physics that deals with the relationships between heat, energy, and temperature. It is fundamental to understanding the behaviour of a physical system, such as an engine. <em>In <a href="https://en.wikipedia.org/wiki/Entropy_(classical_thermodynamics)">classical thermodynamics</a>, entropy is a quantitative, measurable, macroscopic physical property invented to describe heat transfer in systems.</em> Famously, the <a href="https://en.wikipedia.org/wiki/Second_law_of_thermodynamics">second law of thermodynamics</a> says that all processes in a system have a direction, from lower to higher entropy, which reduces the amount of useable energy available. The unusable energy takes the form of heat. This asymmetry within a system can be used empirically to distinguish past and future and establishes entropy as an <a href="https://en.wikipedia.org/wiki/Entropy_as_an_arrow_of_time">arrow of time</a>.</p>
</li><li>
<p><a href="https://en.wikipedia.org/wiki/Statistical_mechanics">Statistical mechanics</a> (also known as statistical thermodynamics) is considered the <a href="https://plato.stanford.edu/entries/statphys-statmech/">third pillar</a> of modern physics, next to quantum theory and relativity theory. It emerged with the development of atomic theories, explaining classical macroscopic thermodynamics as a result of statistical methods applied to large numbers of microscopic entities. <em>In statistical mechanics, entropy is a measure of the number of ways a system can be arranged.</em> Less likely “ordered” arrangements having low entropy, and more likely “unordered” arrangements having high entropy.</p>
</li><li>
<p><a href="https://en.wikipedia.org/wiki/Information_theory">Information theory</a> is a mathematical approach to studying the coding of information for storage and transmission. Information entropy is analogous to statistical mechanics entropy, while being a more <a href="https://en.wikipedia.org/wiki/Entropy_in_thermodynamics_and_information_theory#Theoretical_relationship">general concept</a>. <em>In information theory, entropy is the average level of “<a href="https://en.wikipedia.org/wiki/Information_content">information content</a>” or “surprise” of observed outcomes from a <a href="https://en.wikipedia.org/wiki/Random_variable">random process</a>.</em> For example, flipping a coin 10 times and observing 10 heads is more surprising (and so has higher entropy) than observing a mix of heads and tails, which is less surprising. Another interpretation of information entropy is the amount of information (measured in <a href="https://en.wikipedia.org/wiki/Bit">bits</a>) needed to fully describe a system.</p>
</li></ol>
<p>So entropy has different formulations, and varying interpretations, depending the field it’s used in. Even within a single field entropy can be defined in different ways, as we will see later. However, over time it’s been shown that all formulations are related.</p>

<p>While the concept of entropy may seem abstract, it has many real world applications across physics, chemistry, biological systems, economics, climate change, telecommunications and even the big bang and the arrow of time!</p>
<h2>Deeper Dive into the Different Guises of Entropy</h2>
<p>The following sections take a deeper dive into the concept of entropy in the fields described above. </p>
<h4>1. Classical Thermodynamic Entropy in Physics (Carnot &amp; Clausius)</h4>
<p>In 1865, <a href="https://en.wikipedia.org/wiki/Rudolf_Clausius#Entropy">Rudolf Clausius</a> (1822 - 1888) gave irreversible heat loss a name: Entropy. He was building on the work of <a href="https://en.wikipedia.org/wiki/Nicolas_L%C3%A9onard_Sadi_Carnot">Carnot</a> (1796 - 1832) who laid the foundations of the discipline of thermodynamics while looking to improve the performance of steam engines. <a href="https://en.wikipedia.org/wiki/Thermodynamics#Classical_thermodynamics">Classical thermodynamics</a> is the description of systems near-equilibrium using macroscopic, measurable properties. It models exchanges of energy, work and heat based on the laws of thermodynamics. The qualifier classical reflects the fact that it represents the first level of understanding of the subject as it developed in the 19th century and describes the changes of a system in terms of macroscopic parameters.</p>
<div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F830bd094-8b42-4e2a-abf5-e9101980b70f_800x533.jpeg"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F830bd094-8b42-4e2a-abf5-e9101980b70f_800x533.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F830bd094-8b42-4e2a-abf5-e9101980b70f_800x533.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F830bd094-8b42-4e2a-abf5-e9101980b70f_800x533.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F830bd094-8b42-4e2a-abf5-e9101980b70f_800x533.jpeg 1456w" sizes="100vw"><img src="https://substack-post-media.s3.amazonaws.com/public/images/830bd094-8b42-4e2a-abf5-e9101980b70f_800x533.jpeg" width="450" height="299.8125" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/830bd094-8b42-4e2a-abf5-e9101980b70f_800x533.jpeg&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:533,&quot;width&quot;:800,&quot;resizeWidth&quot;:450,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;File:Justice-2060093 1920.jpg&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt="File:Justice-2060093 1920.jpg" title="File:Justice-2060093 1920.jpg" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F830bd094-8b42-4e2a-abf5-e9101980b70f_800x533.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F830bd094-8b42-4e2a-abf5-e9101980b70f_800x533.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F830bd094-8b42-4e2a-abf5-e9101980b70f_800x533.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F830bd094-8b42-4e2a-abf5-e9101980b70f_800x533.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="#FFFFFF" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" y1="3" x2="14" y2="10"></line><line x1="3" y1="21" x2="10" y2="14"></line></svg></div></div></a><figcaption class="image-caption caption"><a href="https://en.wikipedia.org/wiki/Laws_of_thermodynamics">laws of thermodynamics</a> (<a href="https://en.wikipedia.org/wiki/File:Justice-2060093_1920.jpg">image source</a>)</figcaption></figure></div>
<p>There are 4 <a href="https://en.wikipedia.org/wiki/Laws_of_thermodynamics">laws of thermodynamics</a>. The <a href="https://en.wikipedia.org/wiki/Second_law_of_thermodynamics">second law</a> establishes the concept of entropy as a physical property of a thermodynamic system and states that if a physical process is irreversible, the combined entropy of the system and the environment must increase. Importantly this implies that a <a href="https://en.wikipedia.org/wiki/Perpetual_motion#Classification">perpetual motion machine</a> is physically impossible. For a reversible process which is free of dissipative losses, total entropy may be conserved, however such physical systems cannot exist. The <a href="https://en.wikipedia.org/wiki/Carnot_cycle">Carnot cycle</a> is an idealised reversible process that provides a theoretical upper limit on the efficiency of any classical thermodynamic engine.</p>

<p>The 1865 paper where Clausius introduced the concept of entropy ends with the following summary of the first and second laws of thermodynamics:</p>
<blockquote>
<p>The energy of the universe is constant.<br>The entropy of the universe tends to a maximum.</p>
</blockquote>
<p>Clausius also gives the expression for the <a href="https://en.wikipedia.org/wiki/Entropy_production#Short_history">entropy production</a> for a cyclical process in a closed system, which he denotes by N. Here Q is the quantity of heat, T is the temperature, S is the final state entropy and S<sub>0</sub> the initial state entropy. S<sub>0</sub> - S is the entropy difference for the backwards part of the process. The integral is to be taken from the initial state to the final state, giving the entropy difference for the forwards part of the process. From the context, it is clear that N = 0 if the process is reversible and N &gt; 0 in case of an irreversible process.</p>
<div class="captioned-image-container"><figure><a class="image-link image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffc518622-1d0c-44af-aac5-34150de29cb3_21x5.svg"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffc518622-1d0c-44af-aac5-34150de29cb3_21x5.svg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffc518622-1d0c-44af-aac5-34150de29cb3_21x5.svg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffc518622-1d0c-44af-aac5-34150de29cb3_21x5.svg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffc518622-1d0c-44af-aac5-34150de29cb3_21x5.svg 1456w" sizes="100vw"><img src="https://substack-post-media.s3.amazonaws.com/public/images/fc518622-1d0c-44af-aac5-34150de29cb3_21x5.svg" width="311" height="82.44917582417582" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fc518622-1d0c-44af-aac5-34150de29cb3_21x5.svg&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:386,&quot;width&quot;:1456,&quot;resizeWidth&quot;:311,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;N=S-S_{0}-\\int {\\frac  {dQ}{T}}.&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt="N=S-S_{0}-\int {\frac  {dQ}{T}}." title="N=S-S_{0}-\int {\frac  {dQ}{T}}." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffc518622-1d0c-44af-aac5-34150de29cb3_21x5.svg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffc518622-1d0c-44af-aac5-34150de29cb3_21x5.svg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffc518622-1d0c-44af-aac5-34150de29cb3_21x5.svg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffc518622-1d0c-44af-aac5-34150de29cb3_21x5.svg 1456w" sizes="100vw" loading="lazy"></picture><div></div></div></a><figcaption class="image-caption caption">Expression for the <a href="https://en.wikipedia.org/wiki/Entropy_production#Short_history">entropy production</a> for a cyclical process in a closed system (1865)</figcaption></figure></div>
<p>Next we shift gears from the macroscopic to the microscopic realm…</p>
<h4>2. Statistical Mechanics Entropy in Physics (Gibbs &amp; Boltzmann)</h4>
<p><a href="https://en.wikipedia.org/wiki/Statistical_mechanics">Statistical mechanics</a>, also known as statistical thermodynamics, emerged with the development of atomic and molecular theories in the late 19th century and early 20th century. It supplemented classical thermodynamics with an interpretation of the microscopic interactions between individual particles and relates the microscopic properties of individual atoms to the macroscopic, bulk properties of materials that can be observed on the human scale, thereby explaining classical thermodynamics as a natural result of statistics and classical mechanics. It is a mathematical framework that applies statistical methods and probability theory to large assemblies of microscopic entities. It does not assume or postulate any natural laws, but explains the macroscopic behaviour of nature from the behaviour of such ensembles.</p>

<p><a href="https://en.wikipedia.org/wiki/Josiah_Willard_Gibbs">Josiah Willard Gibbs</a> (1839 - 1903) coined the term statistical mechanics which explains the laws of thermodynamics as consequences of the statistical properties of the possible states of a physical system which is composed of many particles. In Elementary Principles in Statistical Mechanics (1902), which is considered to be the foundation of modern statistical mechanics, he writes:</p>
<blockquote>
<p>Although, as a matter of history, statistical mechanics owes its origin<br>to investigations in thermodynamics, it seems eminently worthy of an<br>independent development, both on account of the elegance and simplicity<br>of its principles, and because it yields new results and places old truths<br>in a new light. - Gibbs</p>
</blockquote>
<p><a href="https://en.wikipedia.org/wiki/Ludwig_Boltzmann">Ludwig Boltzmann</a> (1844 - 1906) is the other leading figure of statistical mechanics and developed the statistical explanation of the second law of thermodynamics. In 1877 he provided what is known as the Boltzmann definition of entropy, S: </p>
<div class="captioned-image-container"><figure><a class="image-link image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faef0feb8-3602-46ee-a082-35fcef4e286e_11x2.svg"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faef0feb8-3602-46ee-a082-35fcef4e286e_11x2.svg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faef0feb8-3602-46ee-a082-35fcef4e286e_11x2.svg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faef0feb8-3602-46ee-a082-35fcef4e286e_11x2.svg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faef0feb8-3602-46ee-a082-35fcef4e286e_11x2.svg 1456w" sizes="100vw"><img src="https://substack-post-media.s3.amazonaws.com/public/images/aef0feb8-3602-46ee-a082-35fcef4e286e_11x2.svg" width="193" height="42.019917582417584" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/aef0feb8-3602-46ee-a082-35fcef4e286e_11x2.svg&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:317,&quot;width&quot;:1456,&quot;resizeWidth&quot;:193,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;S=k_{{{\\rm {B}}}}\\ln \\Omega \\!&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt="S=k_{{{\rm {B}}}}\ln \Omega \!" title="S=k_{{{\rm {B}}}}\ln \Omega \!" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faef0feb8-3602-46ee-a082-35fcef4e286e_11x2.svg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faef0feb8-3602-46ee-a082-35fcef4e286e_11x2.svg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faef0feb8-3602-46ee-a082-35fcef4e286e_11x2.svg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faef0feb8-3602-46ee-a082-35fcef4e286e_11x2.svg 1456w" sizes="100vw" loading="lazy"></picture><div></div></div></a><figcaption class="image-caption caption">Boltzmann entropy (1877)</figcaption></figure></div>
<p>where Ω is the number of distinct microscopic states available to the system given a fixed total energy, and <em>k</em><sub>B</sub> the <a href="https://en.wikipedia.org/wiki/Boltzmann_constant">Boltzmann constant</a>. The Boltzmann constant, and therefore Boltzmann entropy, have dimensions of energy divided by temperature, which has a unit of joules per kelvin (J⋅K<sup>−1</sup>) or kg⋅m<sup>2</sup>⋅s<sup>−2</sup>⋅K<sup>−1</sup> in terms of base units. It could have been chosen to have any value, including 1 (i.e. dimensionless), however for historical reasons it was chosen to have the value: <em>k</em><sub>B</sub> = 1.38649 × 10<sup>−23</sup> joules per kelvin. As described by <a href="https://physics.stackexchange.com/questions/231017/is-the-boltzmann-constant-really-that-important/231065#231065">danielsank</a>, <em>k</em><sub>B</sub> only exists because people defined temperature and entropy before they understood statistical mechanics. If temperature had dimensions of energy, then under this definition entropy would have been dimensionless.</p>

<p>Gibbs refined this formulation and generalised Boltzmann's statistical interpretation of entropy in his work <em><a href="https://en.wikipedia.org/wiki/Elementary_Principles_in_Statistical_Mechanics">Elementary Principles in Statistical Mechanics</a> (1902) </em>by defining the entropy of an arbitrary ensemble as:</p>
<div class="captioned-image-container"><figure><a class="image-link image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fc09923-1cb4-43f7-b9cc-bb891feeef2a_20x5.svg"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fc09923-1cb4-43f7-b9cc-bb891feeef2a_20x5.svg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fc09923-1cb4-43f7-b9cc-bb891feeef2a_20x5.svg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fc09923-1cb4-43f7-b9cc-bb891feeef2a_20x5.svg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fc09923-1cb4-43f7-b9cc-bb891feeef2a_20x5.svg 1456w" sizes="100vw"><img src="https://substack-post-media.s3.amazonaws.com/public/images/3fc09923-1cb4-43f7-b9cc-bb891feeef2a_20x5.svg" width="303" height="81.36881868131869" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3fc09923-1cb4-43f7-b9cc-bb891feeef2a_20x5.svg&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:391,&quot;width&quot;:1456,&quot;resizeWidth&quot;:303,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;S=-k_{{\\text{B}}}\\,\\sum _{i}p_{i}\\ln \\,p_{i}&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt="S=-k_{{\text{B}}}\,\sum _{i}p_{i}\ln \,p_{i}" title="S=-k_{{\text{B}}}\,\sum _{i}p_{i}\ln \,p_{i}" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fc09923-1cb4-43f7-b9cc-bb891feeef2a_20x5.svg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fc09923-1cb4-43f7-b9cc-bb891feeef2a_20x5.svg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fc09923-1cb4-43f7-b9cc-bb891feeef2a_20x5.svg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fc09923-1cb4-43f7-b9cc-bb891feeef2a_20x5.svg 1456w" sizes="100vw" loading="lazy"></picture><div></div></div></a><figcaption class="image-caption caption">Gibbs entropy (1902)</figcaption></figure></div>
<p>where <em>k</em><sub>B</sub> is the <a href="https://en.wikipedia.org/wiki/Boltzmann_constant">Boltzmann constant</a>, while the sum is over all possible <a href="https://en.wikipedia.org/wiki/Microstate_(statistical_mechanics)">microstates</a> i, with <em>p</em><sub>i </sub>the corresponding probability of the microstate. Both Boltzmann and Gibbs entropies are the pillars of the foundation of statistical mechanics and are the basis of all the entropy concepts in modern physics.</p>

<p>As described by <a href="https://physics.stackexchange.com/questions/141321/what-is-the-conceptual-difference-between-gibbs-and-boltzmann-entropies/141324#141324">ACuriousMind</a>, the Gibbs entropy is the generalisation of the Boltzmann entropy holding for all systems, while the Boltzmann entropy is only the entropy if the system is in global <a href="https://en.wikipedia.org/wiki/Thermodynamic_equilibrium">thermodynamical equilibrium</a> (when there is no net macroscopic flows of matter or energy within the system). Both are a measure for the microstates available to a system, but the Gibbs entropy does not require the system to be in a single, well-defined macrostate.</p>

<p>The <a href="https://en.wikipedia.org/wiki/Second_law_of_thermodynamics">second law of thermodynamics</a> states that the total entropy of an isolated system always increases over time. It is a statistical law rather than an absolute law. The statistical nature arises from the fact that it is based on the probability of different configurations of the particles in a system, and how those probabilities change over time. It is not impossible, in principle, for all atoms in a box of a gas to spontaneously migrate to one half; it is only astronomically unlikely.</p>

<p>Entropy is one of the few quantities in the physical sciences that require a particular direction for time and provides a natural explanation for why we observe an <a href="https://en.wikipedia.org/wiki/Entropy_as_an_arrow_of_time">arrow of time</a> in the universe. It explains why systems tend to become more disordered over time, and why we perceive time as having a certain direction from past to future. In cosmology, the <a href="https://en.wikipedia.org/wiki/Past_hypothesis">past hypothesis</a> postulates that the universe started in a low-entropy state which was highly ordered and uniform and this is responsible for the observed structure and organisation of the universe today which is compatible with the second law. At the other end of the spectrum, the <a href="https://en.wikipedia.org/wiki/Heat_death_of_the_universe">heat death of the universe</a> is a hypothesis on the fate of the universe stating the universe will evolve to a state of no thermodynamic free energy, and will therefore be unable to sustain processes that increase entropy. Luckily this should take <a href="https://en.wikipedia.org/wiki/Future_of_an_expanding_universe#Dark_Era_and_Photon_Age">over 10^100 years</a>. It is <a href="https://en.wikipedia.org/wiki/Heat_death_of_the_universe#Timeframe_for_heat_death">suggested</a> that, over vast periods of time, a spontaneous entropy decrease would eventually occur creating anther universe, but in reality we have no idea. To wrap up the cosmological angle, it’s interesting to note that a black hole has an entropy that is proportional to its surface area, rather than its volume, implying that the entropy increases as it absorbs more matter.</p>

<p>The <a href="https://en.wikipedia.org/wiki/Gibbs_paradox">Gibbs paradox</a> is a thought experiment puzzle in statistical mechanics that arises from the different ways of counting the number of possible arrangements of particles in a mixture of two identical gases within a box. One way is to assume that particles are distinguishable, while the other assumes they are indistinguishable. These two ways of counting can lead to different predictions for the entropy of the system, and result in a paradox if we are not careful to specify particle distinguishability. The paradox is resolved when we realise that we need to take into account the fact that identical particles can be swapped with each other without changing the overall arrangement. When we do this, we find that the number of possible arrangements for two identical gases is actually greater than the number of possible arrangements for two different gases. This explains why the entropy of a mixture of identical gases is higher than the entropy of a mixture of different gases.</p>

<p>Next we shift gears again, from the physical world to the informational world…</p>
<h4>3. Information and Communication Entropy (Shannon)</h4>
<p>Information theory is the scientific study of the quantification, storage, and communication of information. In 1948, <a href="https://en.wikipedia.org/wiki/Claude_Shannon">Claude Shannon</a> set out to mathematically quantify the statistical nature of “lost information” in phone-line signals. To do this, Shannon developed the very general concept of information entropy which was published in his <em><a href="https://en.wikipedia.org/wiki/A_Mathematical_Theory_of_Communication">A Mathematical Theory of Communication</a></em>. Shannon considered various ways to encode, compress, and transmit messages, and <a href="https://en.wikipedia.org/wiki/Shannon%27s_source_coding_theorem">proved</a> that the entropy represents an absolute mathematical limit on how well data from a source can be losslessly compressed onto a perfectly noiseless channel.</p>
<div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75f2c65c-c778-42e4-8e50-f1c26e4cf417_757x600.png"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75f2c65c-c778-42e4-8e50-f1c26e4cf417_757x600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75f2c65c-c778-42e4-8e50-f1c26e4cf417_757x600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75f2c65c-c778-42e4-8e50-f1c26e4cf417_757x600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75f2c65c-c778-42e4-8e50-f1c26e4cf417_757x600.png 1456w" sizes="100vw"><img src="https://substack-post-media.s3.amazonaws.com/public/images/75f2c65c-c778-42e4-8e50-f1c26e4cf417_757x600.png" width="584" height="462.8797886393659" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/75f2c65c-c778-42e4-8e50-f1c26e4cf417_757x600.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:600,&quot;width&quot;:757,&quot;resizeWidth&quot;:584,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;File:Pioneer plaque (transparent).svg&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt="File:Pioneer plaque (transparent).svg" title="File:Pioneer plaque (transparent).svg" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75f2c65c-c778-42e4-8e50-f1c26e4cf417_757x600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75f2c65c-c778-42e4-8e50-f1c26e4cf417_757x600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75f2c65c-c778-42e4-8e50-f1c26e4cf417_757x600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75f2c65c-c778-42e4-8e50-f1c26e4cf417_757x600.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="#FFFFFF" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" y1="3" x2="14" y2="10"></line><line x1="3" y1="21" x2="10" y2="14"></line></svg></div></div></a><figcaption class="image-caption caption">The <a href="https://en.wikipedia.org/wiki/Pioneer_plaque">Pioneer plaque</a> (<a href="https://en.wikipedia.org/wiki/File:Pioneer_plaque_(transparent).svg">image source</a>)</figcaption></figure></div>
<p>The core idea of information theory is that the “informational value” of a  message depends on the degree to which the content of the message is surprising. If a highly likely event occurs, the message carries very little information. However, if a highly unlikely event occurs, the message is much more informative. Information theory often concerns itself with measures of information of the distributions associated with <a href="https://en.wikipedia.org/wiki/Random_variable">random variables</a>. The entropy of a random variable is the average level of “information”, “surprise”, or “uncertainty” inherent to the variable's possible outcomes.</p>

<p><a href="https://en.wikipedia.org/wiki/Entropy_(information_theory)">Shannon entropy</a>, H, can be defined as:</p>
<div class="captioned-image-container"><figure><a class="image-link image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7266d127-c4ac-430f-af4b-06f47f1db6bf_28x5.svg"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7266d127-c4ac-430f-af4b-06f47f1db6bf_28x5.svg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7266d127-c4ac-430f-af4b-06f47f1db6bf_28x5.svg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7266d127-c4ac-430f-af4b-06f47f1db6bf_28x5.svg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7266d127-c4ac-430f-af4b-06f47f1db6bf_28x5.svg 1456w" sizes="100vw"><img src="https://substack-post-media.s3.amazonaws.com/public/images/7266d127-c4ac-430f-af4b-06f47f1db6bf_28x5.svg" width="350" height="69.47115384615384" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7266d127-c4ac-430f-af4b-06f47f1db6bf_28x5.svg&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:289,&quot;width&quot;:1456,&quot;resizeWidth&quot;:350,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;{\\displaystyle \\mathrm {H} (X)=-\\sum _{x\\in {\\mathcal {X}}}p(x)\\log _{b}p(x),}&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt="{\displaystyle \mathrm {H} (X)=-\sum _{x\in {\mathcal {X}}}p(x)\log _{b}p(x),}" title="{\displaystyle \mathrm {H} (X)=-\sum _{x\in {\mathcal {X}}}p(x)\log _{b}p(x),}" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7266d127-c4ac-430f-af4b-06f47f1db6bf_28x5.svg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7266d127-c4ac-430f-af4b-06f47f1db6bf_28x5.svg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7266d127-c4ac-430f-af4b-06f47f1db6bf_28x5.svg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7266d127-c4ac-430f-af4b-06f47f1db6bf_28x5.svg 1456w" sizes="100vw" loading="lazy"></picture><div></div></div></a><figcaption class="image-caption caption">Shannon entropy (1948)</figcaption></figure></div>
<p>where <em>p(x)</em> is the probability of outcome <em>x</em> and <em>b</em> is the logarithm base, where b = 2 encodes binary digits. </p>
<div class="captioned-image-container"><figure><a class="image-link image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0472d499-8de3-40f9-9309-1031ecd83e13_200x200.png"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0472d499-8de3-40f9-9309-1031ecd83e13_200x200.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0472d499-8de3-40f9-9309-1031ecd83e13_200x200.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0472d499-8de3-40f9-9309-1031ecd83e13_200x200.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0472d499-8de3-40f9-9309-1031ecd83e13_200x200.png 1456w" sizes="100vw"><img src="https://substack-post-media.s3.amazonaws.com/public/images/0472d499-8de3-40f9-9309-1031ecd83e13_200x200.png" width="320" height="320" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0472d499-8de3-40f9-9309-1031ecd83e13_200x200.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:200,&quot;width&quot;:200,&quot;resizeWidth&quot;:320,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0472d499-8de3-40f9-9309-1031ecd83e13_200x200.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0472d499-8de3-40f9-9309-1031ecd83e13_200x200.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0472d499-8de3-40f9-9309-1031ecd83e13_200x200.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0472d499-8de3-40f9-9309-1031ecd83e13_200x200.png 1456w" sizes="100vw" loading="lazy"></picture><div></div></div></a><figcaption class="image-caption caption">Entropy Η(<em>X</em>) of a coin flip, measured in bits, graphed versus the bias of the coin Pr(<em>X</em> = Heads) (<a href="https://upload.wikimedia.org/wikipedia/commons/thumb/2/22/Binary_entropy_plot.svg/400px-Binary_entropy_plot.svg.png">source</a>)</figcaption></figure></div>
<p>Shannon entropy is clearly analogous to Gibbs entropy, without the Boltzmann constant. The analogy results when the values of the random variable designate energies of microstates. In the view of <a href="https://en.wikipedia.org/wiki/Edwin_Thompson_Jaynes">Jaynes</a>, entropy within statistical mechanics should be seen as an <a href="https://en.wikipedia.org/wiki/Entropy_(information_theory)#Relationship_to_thermodynamic_entropy">application of Shannon's information theory</a>: the thermodynamic entropy is interpreted as being proportional to the amount of further Shannon information needed to define the detailed microscopic state of the system, that remains uncommunicated by a description solely in terms of the macroscopic variables of classical thermodynamics. For example, adding heat to a system increases its thermodynamic entropy because it increases the number of possible microscopic states of the system that are consistent with the measurable values of its macroscopic variables, making any complete state description longer.</p>

<p><a href="https://en.wikipedia.org/wiki/Maxwell%27s_demon">Maxwell's demon</a> is a thought experiment, proposed in 1867, that would hypothetically violate the second law of thermodynamics. In the experiment a demon controls a door between two chambers of gas. As gas molecules approach the door, the demon allows only fast-moving molecules through in one direction, and slow-moving in the other direction, causing one chamber to warm up and the other to cool down. This decreases the total entropy of the system, without applying any work, hence the violation. It stimulated work on the relationship between thermodynamics and information theory.</p>
<div class="captioned-image-container"><figure><a class="image-link image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6723eea-a1ec-40f6-95bc-78daa38bb15c_340x125.png"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6723eea-a1ec-40f6-95bc-78daa38bb15c_340x125.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6723eea-a1ec-40f6-95bc-78daa38bb15c_340x125.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6723eea-a1ec-40f6-95bc-78daa38bb15c_340x125.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6723eea-a1ec-40f6-95bc-78daa38bb15c_340x125.png 1456w" sizes="100vw"><img src="https://substack-post-media.s3.amazonaws.com/public/images/b6723eea-a1ec-40f6-95bc-78daa38bb15c_340x125.png" width="600" height="220.58823529411765" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b6723eea-a1ec-40f6-95bc-78daa38bb15c_340x125.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:125,&quot;width&quot;:340,&quot;resizeWidth&quot;:600,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6723eea-a1ec-40f6-95bc-78daa38bb15c_340x125.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6723eea-a1ec-40f6-95bc-78daa38bb15c_340x125.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6723eea-a1ec-40f6-95bc-78daa38bb15c_340x125.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6723eea-a1ec-40f6-95bc-78daa38bb15c_340x125.png 1456w" sizes="100vw" loading="lazy"></picture><div></div></div></a><figcaption class="image-caption caption">Schematic figure of Maxwell's demon thought experiment (<a href="https://en.wikipedia.org/wiki/File:Maxwell%27s_demon.svg">source</a>)</figcaption></figure></div>
<p>Maxwell's demon can (hypothetically) reduce the thermodynamic entropy of a system by using information about the states of individual molecules; but, as <a href="https://en.wikipedia.org/wiki/Rolf_Landauer">Landauer</a> showed in 1961, to function the demon himself must increase thermodynamic entropy in the process, by at least the amount of <a href="https://en.wikipedia.org/wiki/Information_content">Shannon information</a> he proposes to first acquire and store; and so the total thermodynamic entropy does not decrease (which resolves the paradox). <a href="https://en.wikipedia.org/wiki/Landauer%27s_principle">Landauer's principle</a> is a physical principle pertaining to the lower theoretical limit of energy consumption of computation. It imposes a lower bound on the amount of heat a computer must generate to process a given amount of information, though modern computers are far less efficient.</p>

<p>The <a href="https://en.wikipedia.org/wiki/Principle_of_maximum_entropy">principle of maximum entropy</a> states that the probability distribution which best represents the current state of knowledge about a system is the one with largest entropy, in the context of precisely stated prior data. The principle was first expounded by Jaynes where he emphasised a natural correspondence between statistical mechanics and information theory. It can be said to express a claim of maximum ignorance. The selected distribution is the one that makes the <em>least claim</em> to being informed beyond the stated prior data, that is to say the one that admits the most ignorance beyond the stated prior data.</p>

<p>The principle of maximum entropy is commonly applied to inferential problems, for example, to obtain prior probability distributions for Bayesian inference or making predictions with <a href="https://en.wikipedia.org/wiki/Logistic_regression#Maximum_entropy">logistic regression</a>, which corresponds to the maximum entropy classifier for independent observations. Giffin and <a href="https://en.wikipedia.org/wiki/Ariel_Caticha">Caticha</a> (2007) state that Bayes' theorem and the principle of maximum entropy are completely compatible and can be seen as special cases of the “method of maximum relative entropy”. Jaynes <a href="https://bayes.wustl.edu/etj/articles/relationship.pdf">stated</a>, in 1988, that Bayes' theorem was a way to calculate a probability, while maximum entropy was a way to assign a prior probability distribution.</p>
<h2>A Review of Different Entropy Measures</h2>
<p>We’ve touched upon the key measures of entropy as the concept matured and generalised since around 1865. There are many additional definitions that are related to each other in different ways.</p>

<p><a href="https://doi.org/10.3390/e23020222">The Entropy Universe</a> (2021) by Ribeiro et al, is a paper which aims to review the many variants of entropy definitions and how they relate to each other. The authors describe the relationship between the most applied entropies for different scientific fields, establishing bases for researchers to properly choose the variant of entropy most suitable for their data. It’s well worth checking out.</p>

<p>For example, here is the timeline (in logarithmic scale) of the universe of entropies covered in the paper:</p>
<div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ef05846-f9b7-422e-8612-24ee3088170f_1262x560.png"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ef05846-f9b7-422e-8612-24ee3088170f_1262x560.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ef05846-f9b7-422e-8612-24ee3088170f_1262x560.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ef05846-f9b7-422e-8612-24ee3088170f_1262x560.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ef05846-f9b7-422e-8612-24ee3088170f_1262x560.png 1456w" sizes="100vw"><img src="https://substack-post-media.s3.amazonaws.com/public/images/2ef05846-f9b7-422e-8612-24ee3088170f_1262x560.png" width="1262" height="560" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2ef05846-f9b7-422e-8612-24ee3088170f_1262x560.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:560,&quot;width&quot;:1262,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ef05846-f9b7-422e-8612-24ee3088170f_1262x560.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ef05846-f9b7-422e-8612-24ee3088170f_1262x560.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ef05846-f9b7-422e-8612-24ee3088170f_1262x560.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ef05846-f9b7-422e-8612-24ee3088170f_1262x560.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="#FFFFFF" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" y1="3" x2="14" y2="10"></line><line x1="3" y1="21" x2="10" y2="14"></line></svg></div></div></a><figcaption class="image-caption caption">Timeline of the universe of entropies discussed in “<a href="https://doi.org/10.3390/e23020222">The Entropy Universe</a>”, 2021</figcaption></figure></div>
<p>And here is the full entropy relation diagram, which can be found on page 21:</p>
<div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6285f654-a1e5-46d6-9173-b9584c3d34b1_1112x1187.png"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6285f654-a1e5-46d6-9173-b9584c3d34b1_1112x1187.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6285f654-a1e5-46d6-9173-b9584c3d34b1_1112x1187.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6285f654-a1e5-46d6-9173-b9584c3d34b1_1112x1187.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6285f654-a1e5-46d6-9173-b9584c3d34b1_1112x1187.png 1456w" sizes="100vw"><img src="https://substack-post-media.s3.amazonaws.com/public/images/6285f654-a1e5-46d6-9173-b9584c3d34b1_1112x1187.png" width="696" height="742.9424460431654" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6285f654-a1e5-46d6-9173-b9584c3d34b1_1112x1187.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1187,&quot;width&quot;:1112,&quot;resizeWidth&quot;:696,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6285f654-a1e5-46d6-9173-b9584c3d34b1_1112x1187.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6285f654-a1e5-46d6-9173-b9584c3d34b1_1112x1187.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6285f654-a1e5-46d6-9173-b9584c3d34b1_1112x1187.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6285f654-a1e5-46d6-9173-b9584c3d34b1_1112x1187.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="#FFFFFF" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" y1="3" x2="14" y2="10"></line><line x1="3" y1="21" x2="10" y2="14"></line></svg></div></div></a><figcaption class="image-caption caption">Full entropy relation diagram discussed in “<a href="https://doi.org/10.3390/e23020222">The Entropy Universe</a>”, 2021</figcaption></figure></div><h2>The People Behind Entropy</h2>
<p>It’s helpful to understand the timeline over which concept of entropy has evolved, from 19th century combustion engines to modern communications.</p>

<p>In the 19th century people were building combustion engines and observed that some energy released from combustion reactions was always lost and not transformed into useful work. Investigations into trying to solve this problem led to the initial concept of entropy.</p>
<h3><a href="https://en.wikipedia.org/wiki/Nicolas_L%C3%A9onard_Sadi_Carnot">Nicolas Léonard Sadi Carnot</a> (1796 - 1832; thermodynamics)</h3>
<p>Carnot was a French mechanical engineer and the “<em><strong>father of thermodynamics</strong></em>”. His work was used by Clausius and Kelvin to formalise the second law of thermodynamics and define the concept of entropy.</p>
<h3><a href="https://en.wikipedia.org/wiki/Rudolf_Clausius">Rudolf Clausius</a> (1822 - 1888; thermodynamics)</h3><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1249dc7-f22c-4aad-b885-f577b1fab01e_220x337.jpeg"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1249dc7-f22c-4aad-b885-f577b1fab01e_220x337.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1249dc7-f22c-4aad-b885-f577b1fab01e_220x337.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1249dc7-f22c-4aad-b885-f577b1fab01e_220x337.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1249dc7-f22c-4aad-b885-f577b1fab01e_220x337.jpeg 1456w" sizes="100vw"><img src="https://substack-post-media.s3.amazonaws.com/public/images/e1249dc7-f22c-4aad-b885-f577b1fab01e_220x337.jpeg" width="206" height="315.55454545454546" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e1249dc7-f22c-4aad-b885-f577b1fab01e_220x337.jpeg&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:337,&quot;width&quot;:220,&quot;resizeWidth&quot;:206,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Rudolf Clausius 01.jpg&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt="Rudolf Clausius 01.jpg" title="Rudolf Clausius 01.jpg" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1249dc7-f22c-4aad-b885-f577b1fab01e_220x337.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1249dc7-f22c-4aad-b885-f577b1fab01e_220x337.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1249dc7-f22c-4aad-b885-f577b1fab01e_220x337.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1249dc7-f22c-4aad-b885-f577b1fab01e_220x337.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="#FFFFFF" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" y1="3" x2="14" y2="10"></line><line x1="3" y1="21" x2="10" y2="14"></line></svg></div></div></a><figcaption class="image-caption caption">Rudolf Clausius (<a href="https://en.wikipedia.org/wiki/File:Rudolf_Clausius_01.jpg">image source</a>)</figcaption></figure></div>
<p>In 1865 Clausius, a German physicist, <em><strong>introduced and named the concept of entropy</strong></em>. He studied the mechanical theory of heat and built upon Carnot’s work. His most important paper, “On the Moving Force of Heat” first stated the basic ideas of the second law of thermodynamics.</p>
<h3><a href="https://en.wikipedia.org/wiki/William_Thomson,_1st_Baron_Kelvin#Thermodynamics">William Thomson (Lord Kelvin)</a> (1824 - 1907; thermodynamics)</h3>
<p>Kelvin did important work in the mathematics of electricity and formulation of the first and second laws of thermodynamics, and did much to unify the emerging discipline of physics in its contemporary form. He also <em><strong>coined term thermodynamics</strong></em> in his publication “An Account of Carnot's Theory of the Motive Power of Heat”.</p>
<h3><a href="https://en.wikipedia.org/wiki/James_Clerk_Maxwell">James Clerk Maxwell</a> (1831 - 1879; statistical mechanics)</h3>
<p>Maxwell, was a Scottish mathematician and scientist, helped develop the <a href="https://en.wikipedia.org/wiki/Maxwell%E2%80%93Boltzmann_distribution">Maxwell–Boltzmann distribution</a> - a statistical means of describing aspects of the kinetic theory of gases. Also proposed “<em><strong>Maxwell's demon</strong></em>” a paradoxical thought experiment where entropy decreases.</p>
<h3><a href="https://en.wikipedia.org/wiki/Ludwig_Boltzmann">Ludwig Boltzmann</a> (1844 - 1906; statistical mechanics)</h3><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fe28b44-820c-4f55-986a-af2e44154fd9_225x276.jpeg"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fe28b44-820c-4f55-986a-af2e44154fd9_225x276.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fe28b44-820c-4f55-986a-af2e44154fd9_225x276.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fe28b44-820c-4f55-986a-af2e44154fd9_225x276.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fe28b44-820c-4f55-986a-af2e44154fd9_225x276.jpeg 1456w" sizes="100vw"><img src="https://substack-post-media.s3.amazonaws.com/public/images/9fe28b44-820c-4f55-986a-af2e44154fd9_225x276.jpeg" width="215" height="263.73333333333335" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9fe28b44-820c-4f55-986a-af2e44154fd9_225x276.jpeg&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:276,&quot;width&quot;:225,&quot;resizeWidth&quot;:215,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Boltzmann2.jpg&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt="Boltzmann2.jpg" title="Boltzmann2.jpg" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fe28b44-820c-4f55-986a-af2e44154fd9_225x276.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fe28b44-820c-4f55-986a-af2e44154fd9_225x276.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fe28b44-820c-4f55-986a-af2e44154fd9_225x276.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fe28b44-820c-4f55-986a-af2e44154fd9_225x276.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="#FFFFFF" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" y1="3" x2="14" y2="10"></line><line x1="3" y1="21" x2="10" y2="14"></line></svg></div></div></a><figcaption class="image-caption caption">Ludwig Eduard Boltzmann (<a href="https://en.wikipedia.org/wiki/File:Boltzmann2.jpg">image source</a>)</figcaption></figure></div>
<p>Boltzmann, an Austrian physicist and philosopher, developed the statistical explanation of the second law of thermodynamics. He also developed the fundamental<em><strong> </strong></em>statistical interpretation of entropy (<em><strong>Boltzmann entropy</strong></em>) in terms of a collection of microstates.</p>
<h3><a href="https://en.wikipedia.org/wiki/Josiah_Willard_Gibbs">Josiah Willard Gibbs - Wikipedia</a> (1839 - 1903; statistical mechanics)</h3><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffeeecdad-3a3e-40df-aac2-ceb72b1cfbd3_220x293.jpeg"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffeeecdad-3a3e-40df-aac2-ceb72b1cfbd3_220x293.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffeeecdad-3a3e-40df-aac2-ceb72b1cfbd3_220x293.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffeeecdad-3a3e-40df-aac2-ceb72b1cfbd3_220x293.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffeeecdad-3a3e-40df-aac2-ceb72b1cfbd3_220x293.jpeg 1456w" sizes="100vw"><img src="https://substack-post-media.s3.amazonaws.com/public/images/feeecdad-3a3e-40df-aac2-ceb72b1cfbd3_220x293.jpeg" width="222" height="295.6636363636364" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/feeecdad-3a3e-40df-aac2-ceb72b1cfbd3_220x293.jpeg&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:293,&quot;width&quot;:220,&quot;resizeWidth&quot;:222,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Portrait of Josiah Willard Gibbs&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt="Portrait of Josiah Willard Gibbs" title="Portrait of Josiah Willard Gibbs" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffeeecdad-3a3e-40df-aac2-ceb72b1cfbd3_220x293.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffeeecdad-3a3e-40df-aac2-ceb72b1cfbd3_220x293.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffeeecdad-3a3e-40df-aac2-ceb72b1cfbd3_220x293.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffeeecdad-3a3e-40df-aac2-ceb72b1cfbd3_220x293.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="#FFFFFF" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" y1="3" x2="14" y2="10"></line><line x1="3" y1="21" x2="10" y2="14"></line></svg></div></div></a><figcaption class="image-caption caption">Josiah Willard Gibbs (<a href="https://en.wikipedia.org/wiki/File:Josiah_Willard_Gibbs_-from_MMS-.jpg">image source</a>)</figcaption></figure></div>
<p>Gibbs, an American scientist, generalised Boltzmann's entropy, so that a system could exchange energy with its surroundings (<em><strong>Gibbs entropy</strong></em><strong>)</strong>. He also <em><strong>coined the term statistical mechanics</strong></em> which explains the laws of thermodynamics as consequences of the statistical properties of the possible states of a physical system which is composed of many particles. His papers from the 1870s introduced the idea of expressing the internal energy of a system in terms of the entropy, in addition to the usual state-variables of volume, pressure, and temperature.</p>
<h3><a href="https://en.wikipedia.org/wiki/John_von_Neumann">John von Neumann</a> (1903 - 1957)</h3>
<p>In physics, the von Neumann entropy, named after John von Neumann, is an extension of the concept of Gibbs entropy from classical statistical mechanics to <em><strong>quantum statistical mechanics</strong></em>.</p>
<h3><a href="https://en.wikipedia.org/wiki/Claude_Shannon">Claude Shannon</a> (1916 - 2001)</h3><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff4bc380c-4eae-4126-8163-51111c6d8029_220x310.jpeg"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff4bc380c-4eae-4126-8163-51111c6d8029_220x310.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff4bc380c-4eae-4126-8163-51111c6d8029_220x310.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff4bc380c-4eae-4126-8163-51111c6d8029_220x310.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff4bc380c-4eae-4126-8163-51111c6d8029_220x310.jpeg 1456w" sizes="100vw"><img src="https://substack-post-media.s3.amazonaws.com/public/images/f4bc380c-4eae-4126-8163-51111c6d8029_220x310.jpeg" width="216" height="304.3636363636364" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f4bc380c-4eae-4126-8163-51111c6d8029_220x310.jpeg&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:310,&quot;width&quot;:220,&quot;resizeWidth&quot;:216,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;ClaudeShannon MFO3807.jpg&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;internalRedirect&quot;:null}" class="sizing-normal" alt="ClaudeShannon MFO3807.jpg" title="ClaudeShannon MFO3807.jpg" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff4bc380c-4eae-4126-8163-51111c6d8029_220x310.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff4bc380c-4eae-4126-8163-51111c6d8029_220x310.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff4bc380c-4eae-4126-8163-51111c6d8029_220x310.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff4bc380c-4eae-4126-8163-51111c6d8029_220x310.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="#FFFFFF" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" y1="3" x2="14" y2="10"></line><line x1="3" y1="21" x2="10" y2="14"></line></svg></div></div></a><figcaption class="image-caption caption">Claude Shannon (<a href="https://en.wikipedia.org/wiki/File:ClaudeShannon_MFO3807.jpg">image source</a>)</figcaption></figure></div>
<p>Known as a "<em><strong>father of information theory</strong></em>".&nbsp; Shannon <em><strong>developed information entropy</strong></em> as a measure of the information content in a message, which is a measure of uncertainty reduced by the message. In so doing, he essentially invented the field of information theory.</p>
<h3><a href="https://en.wikipedia.org/wiki/Edwin_Thompson_Jaynes">Edwin Thompson Jaynes</a> (1922 - 1998)</h3>
<p>Wrote extensively on statistical mechanics and on foundations of probability and statistical inference, initiating in 1957 the <em><strong>maximum entropy interpretation of thermodynamics</strong></em>.</p>
<h2>Final Thoughts</h2>
<p>As stated in the introduction, entropy is a notoriously tricky concept associated with many concepts, and we’ve only scratched the surface on this fascinating concept here.</p>

<p>I’ve certainly enjoyed researching for this post and apologies if it’s a bit rough, but it’s time to click publish and get it out as it’s been sitting in draft for a while.</p>

<p>I hope to write another related post, particularly expanding on Shannon information entropy, <a href="https://en.wikipedia.org/wiki/Quantities_of_information">quantities of information</a>, <a href="https://en.wikipedia.org/wiki/Kolmogorov_complexity">complexity</a>, <a href="https://en.wikipedia.org/wiki/Randomness">randomness</a>, <a href="https://en.wikipedia.org/wiki/Quantum_information">quantum information</a> and how <a href="https://philpapers.org/archive/WHEIPQ.pdf">they’re all related</a>.</p>
<p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://infocruncher.substack.com/p/entropy-a-history-and-introduction?utm_source=substack&utm_medium=email&utm_content=share&action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}"><a class="button primary" href="https://infocruncher.substack.com/p/entropy-a-history-and-introduction?utm_source=substack&utm_medium=email&utm_content=share&action=share"><span>Share</span></a></p>
<h2>Selected Resources</h2>
<p>I’ll wrap up with links to resources I found valuable reading. Thanks for reading this far, I hope you got something out of it!</p>
<ol><li>
<p><a href="https://www.arielcaticha.com/my-book-entropic-physics">Entropic Physics: Probability, Entropy, and the Foundations of Physics</a> (Caticha, 2022)</p>
</li><li>
<p><a href="https://arxiv.org/abs/2107.04529">Entropy, Information, and the Updating of Probabilities</a> (Caticha, 2021)</p>
</li><li>
<p><a href="https://arxiv.org/abs/0808.0012">Lectures on Probability, Entropy, and Statistical Physics</a> (Ariel Caticha, 2008)</p>
</li><li>
<p><a href="https://www.mdpi.com/1099-4300/23/2/222">The Entropy Universe - a timeline of entropies</a> (Ribeiro et al, 2021)</p>
</li><li>
<p><a href="https://arxiv.org/abs/1711.07326">Researchers in an Entropy Wonderland - A Review of the Entropy Concept</a> (Popovic, 2017)</p>
</li><li>
<p><a href="https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf">A Mathematical Theory of Communication</a> (Shannon, 1948)</p>
</li><li>
<p><a href="https://bayes.wustl.edu/etj/articles/theory.1.pdf">Information Theory and Statistical Mechanics</a> (Jaynes, 1957)</p>
</li><li>
<p><a href="https://bayes.wustl.edu/etj/articles/theory.2.pdf">Information Theory and Statistical Mechanics II</a> (Jaynes, 1957)</p>
</li><li>
<p><a href="https://bayes.wustl.edu/etj/articles/brandeis.pdf">Information Theory and Statistical Mechanics - Lecture Notes</a> (Jaynes, 1962)</p>
</li><li>
<p><a href="https://bayes.wustl.edu/etj/articles/stand.on.entropy.pdf">Where do we Stand on Maximum Entropy</a> (Jaynes, 1978)</p>
</li><li>
<p><a href="https://bayes.wustl.edu/etj/articles/relationship.pdf">The Relation of Bayesian and Maximum Entropy Methods</a> (Jaynes, 1988)</p>
</li><li>
<p><a href="https://sites.pitt.edu/~jdnorton/lectures/Rotman_Summer_School_2013/thermo_computing_docs/Landauer_1961.pdf">Irreversibility and heat generation in the computing process</a> (Landauer, 1961)</p>
</li><li>
<p><a href="https://arxiv.org/abs/1209.1025">Is There a Unique Physical Entropy? Micro versus Macro</a> (Dieks, 2012)</p>
</li><li>
<p><a href="https://www.mdpi.com/1099-4300/21/8/742">Entropy? Exercices de Style</a> (Gaudenzi, 2019)</p>
</li><li>
<p><a href="https://arxiv.org/abs/1405.6903">Quantifying the Rise and Fall of Complexity in Closed Systems</a> (Carroll and Aaronson, 2014)</p>
</li><li>
<p><a href="https://en.wikipedia.org/wiki/Entropy_(disambiguation)">Entropy (disambiguation) - Wikipedia</a></p>
</li></ol>


